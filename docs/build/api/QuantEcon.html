<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>QuantEcon · QuantEcon.jl documentation</title><link href="../assets/documenter.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="../assets/documenter.js"></script></head><body><nav class="toc"><h1>QuantEcon.jl</h1><form class="search" action="../search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="../index.html">Home</a></li><li><span class="toctext">API</span><ul><li class="current"><a class="toctext" href="QuantEcon.html">QuantEcon</a><ul class="internal"><li><a class="toctext" href="#Exported-1">Exported</a></li><li><a class="toctext" href="#Internal-1">Internal</a></li><li><a class="toctext" href="#Index-1">Index</a></li></ul></li></ul></li><li><a class="toctext" href="../man/contributing.html">Contributing</a></li></ul></nav><article id="docs"><header><nav><ul><li>API</li><li><a href="QuantEcon.html">QuantEcon</a></li></ul><a class="edit-page" href="https://github.com/stephenbnicar/QuantEcon.jl/tree/60be29a709b3870a53e7e6ff17eeaff0f638ecd0/docs/src/api/QuantEcon.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/></header><h1><a class="nav-anchor" id="QuantEcon-1" href="#QuantEcon-1">QuantEcon</a></h1><p>API documentation</p><ul><li><a href="QuantEcon.html#QuantEcon-1">QuantEcon</a></li><ul><li><a href="QuantEcon.html#Exported-1">Exported</a></li><li><a href="QuantEcon.html#Internal-1">Internal</a></li><li><a href="QuantEcon.html#Index-1">Index</a></li></ul></ul><h2><a class="nav-anchor" id="Exported-1" href="#Exported-1">Exported</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.ARMA" href="#QuantEcon.ARMA"><code>QuantEcon.ARMA</code></a> — <span class="docstring-category">Type</span>.</div><div><p>Represents a scalar ARMA(p, q) process</p><p>If phi and theta are scalars, then the model is understood to be</p><pre><code class="language-none">X_t = phi X_{t-1} + epsilon_t + theta epsilon_{t-1}</code></pre><p>where epsilon_t is a white noise process with standard deviation sigma.</p><p>If phi and theta are arrays or sequences, then the interpretation is the ARMA(p, q) model</p><pre><code class="language-none">X_t = phi_1 X_{t-1} + ... + phi_p X_{t-p} +
epsilon_t + theta_1 epsilon_{t-1} + ...  +
theta_q epsilon_{t-q}</code></pre><p>where</p><ul><li>phi = (phi_1, phi_2,..., phi_p)</li><li>theta = (theta_1, theta_2,..., theta_q)</li><li>sigma is a scalar, the standard deviation of the white noise</li></ul><p><strong>Fields</strong></p><ul><li><code>phi::Vector</code> : AR parameters phi_1, ..., phi_p</li><li><code>theta::Vector</code> : MA parameters theta_1, ..., theta_q</li><li><code>p::Integer</code> : Number of AR coefficients</li><li><code>q::Integer</code> : Number of MA coefficients</li><li><code>sigma::Real</code> : Standard deviation of white noise</li><li><code>ma_poly::Vector</code> : MA polynomial –- filtering representatoin</li><li><code>ar_poly::Vector</code> : AR polynomial –- filtering representation</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia">using QuantEcon
phi = 0.5
theta = [0.0, -0.8]
sigma = 1.0
lp = ARMA(phi, theta, sigma)
require(joinpath(Pkg.dir(&quot;QuantEcon&quot;), &quot;examples&quot;, &quot;arma_plots.jl&quot;))
quad_plot(lp)</code></pre></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.DiscreteDP" href="#QuantEcon.DiscreteDP"><code>QuantEcon.DiscreteDP</code></a> — <span class="docstring-category">Type</span>.</div><div><p>DiscreteDP type for specifying paramters for discrete dynamic programming model</p><p><strong>Parameters</strong></p><ul><li><code>R::Array{T,NR}</code> : Reward Array</li><li><code>Q::Array{T,NQ}</code> : Transition Probability Array</li><li><code>beta::Float64</code>  : Discount Factor</li><li><code>a_indices::Nullable{Vector{Tind}}</code>: Action Indices. Null unless using   SA formulation</li><li><code>a_indptr::Nullable{Vector{Tind}}</code>: Action Index Pointers. Null unless using   SA formulation</li></ul><p><strong>Returns</strong></p><ul><li><code>ddp::DiscreteDP</code> : DiscreteDP object</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.DiscreteDP-Tuple{AbstractArray{T,NR},AbstractArray{T,NQ},Tbeta,Array{Tind,1},Array{Tind,1}}" href="#QuantEcon.DiscreteDP-Tuple{AbstractArray{T,NR},AbstractArray{T,NQ},Tbeta,Array{Tind,1},Array{Tind,1}}"><code>QuantEcon.DiscreteDP</code></a> — <span class="docstring-category">Method</span>.</div><div><p>DiscreteDP type for specifying parameters for discrete dynamic programming model State-Action Pair Formulation</p><p><strong>Parameters</strong></p><ul><li><code>R::Array{T,NR}</code> : Reward Array</li><li><code>Q::Array{T,NQ}</code> : Transition Probability Array</li><li><code>beta::Float64</code>  : Discount Factor</li><li><code>s_indices::Nullable{Vector{Tind}}</code>: State Indices. Null unless using   SA formulation</li><li><code>a_indices::Nullable{Vector{Tind}}</code>: Action Indices. Null unless using   SA formulation</li><li><code>a_indptr::Nullable{Vector{Tind}}</code>: Action Index Pointers. Null unless using   SA formulation</li></ul><p><strong>Returns</strong></p><ul><li><code>ddp::DiscreteDP</code> : Constructor for DiscreteDP object</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.DiscreteDP-Tuple{Array{T,NR},Array{T,NQ},Tbeta}" href="#QuantEcon.DiscreteDP-Tuple{Array{T,NR},Array{T,NQ},Tbeta}"><code>QuantEcon.DiscreteDP</code></a> — <span class="docstring-category">Method</span>.</div><div><p>DiscreteDP type for specifying parameters for discrete dynamic programming model Dense Matrix Formulation</p><p><strong>Parameters</strong></p><ul><li><code>R::Array{T,NR}</code> : Reward Array</li><li><code>Q::Array{T,NQ}</code> : Transition Probability Array</li><li><code>beta::Float64</code>  : Discount Factor</li></ul><p><strong>Returns</strong></p><ul><li><code>ddp::DiscreteDP</code> : Constructor for DiscreteDP object</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.DiscreteRV" href="#QuantEcon.DiscreteRV"><code>QuantEcon.DiscreteRV</code></a> — <span class="docstring-category">Type</span>.</div><div><p>Generates an array of draws from a discrete random variable with vector of probabilities given by q.</p><p><strong>Fields</strong></p><ul><li><code>q::AbstractVector</code>: A vector of non-negative probabilities that sum to 1</li><li><code>Q::AbstractVector</code>: The cumulative sum of q</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.ECDF" href="#QuantEcon.ECDF"><code>QuantEcon.ECDF</code></a> — <span class="docstring-category">Type</span>.</div><div><p>One-dimensional empirical distribution function given a vector of observations.</p><p><strong>Fields</strong></p><ul><li><code>observations::Vector</code>: The vector of observations</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.LAE" href="#QuantEcon.LAE"><code>QuantEcon.LAE</code></a> — <span class="docstring-category">Type</span>.</div><div><p>A look ahead estimator associated with a given stochastic kernel p and a vector of observations X.</p><p><strong>Fields</strong></p><ul><li><code>p::Function</code>: The stochastic kernel. Signature is <code>p(x, y)</code> and it should be vectorized in both inputs</li><li><code>X::Matrix</code>: A vector containing observations. Note that this can be passed as any kind of <code>AbstractArray</code> and will be coerced into an <code>n x 1</code> vector.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.LQ" href="#QuantEcon.LQ"><code>QuantEcon.LQ</code></a> — <span class="docstring-category">Type</span>.</div><div><p>Main constructor for LQ type</p><p>Specifies default argumets for all fields not part of the payoff function or transition equation.</p><p><strong>Arguments</strong></p><ul><li><code>Q::ScalarOrArray</code> : k x k payoff coefficient for control variable u. Must be symmetric and nonnegative definite</li><li><code>R::ScalarOrArray</code> : n x n payoff coefficient matrix for state variable x. Must be symmetric and nonnegative definite</li><li><code>A::ScalarOrArray</code> : n x n coefficient on state in state transition</li><li><code>B::ScalarOrArray</code> : n x k coefficient on control in state transition</li><li><code>;C::ScalarOrArray(zeros(size(R, 1)))</code> : n x j coefficient on random shock in state transition</li><li><code>;N::ScalarOrArray(zeros(size(B,1), size(A, 2)))</code> : k x n cross product in payoff equation</li><li><code>;bet::Real(1.0)</code> : Discount factor in [0, 1]</li><li><code>capT::Union{Int, Void}(Void)</code> : Terminal period in finite horizon problem</li><li><code>rf::ScalarOrArray(fill(NaN, size(R)...))</code> : n x n terminal payoff in finite horizon problem. Must be symmetric and nonnegative definite.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.LQ" href="#QuantEcon.LQ"><code>QuantEcon.LQ</code></a> — <span class="docstring-category">Type</span>.</div><div><p>Linear quadratic optimal control of either infinite or finite horizon</p><p>The infinite horizon problem can be written</p><pre><code class="language-none">min E sum_{t=0}^{infty} beta^t r(x_t, u_t)</code></pre><p>with</p><pre><code class="language-none">r(x_t, u_t) := x_t&#39; R x_t + u_t&#39; Q u_t + 2 u_t&#39; N x_t</code></pre><p>The finite horizon form is</p><pre><code class="language-none">min E sum_{t=0}^{T-1} beta^t r(x_t, u_t) + beta^T x_T&#39; R_f x_T</code></pre><p>Both are minimized subject to the law of motion</p><pre><code class="language-none">x_{t+1} = A x_t + B u_t + C w_{t+1}</code></pre><p>Here x is n x 1, u is k x 1, w is j x 1 and the matrices are conformable for these dimensions.  The sequence {w_t} is assumed to be white noise, with zero mean and E w_t w_t&#39; = I, the j x j identity.</p><p>For this model, the time t value (i.e., cost-to-go) function V_t takes the form</p><pre><code class="language-none">x&#39; P_T x + d_T</code></pre><p>and the optimal policy is of the form u_T = -F_T x_T.  In the infinite horizon case, V, P, d and F are all stationary.</p><p><strong>Fields</strong></p><ul><li><code>Q::ScalarOrArray</code> : k x k payoff coefficient for control variable u. Must be symmetric and nonnegative definite</li><li><code>R::ScalarOrArray</code> : n x n payoff coefficient matrix for state variable x. Must be symmetric and nonnegative definite</li><li><code>A::ScalarOrArray</code> : n x n coefficient on state in state transition</li><li><code>B::ScalarOrArray</code> : n x k coefficient on control in state transition</li><li><code>C::ScalarOrArray</code> : n x j coefficient on random shock in state transition</li><li><code>N::ScalarOrArray</code> : k x n cross product in payoff equation</li><li><code>bet::Real</code> : Discount factor in [0, 1]</li><li><code>capT::Union{Int, Void}</code> : Terminal period in finite horizon problem</li><li><code>rf::ScalarOrArray</code> : n x n terminal payoff in finite horizon problem. Must be symmetric and nonnegative definite</li><li><code>P::ScalarOrArray</code> : n x n matrix in value function representation V(x) = x&#39;Px + d</li><li><code>d::Real</code> : Constant in value function representation</li><li><code>F::ScalarOrArray</code> : Policy rule that specifies optimal control in each period</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.LQ" href="#QuantEcon.LQ"><code>QuantEcon.LQ</code></a> — <span class="docstring-category">Type</span>.</div><div><p>Version of default constuctor making <code>bet</code> <code>capT</code> <code>rf</code> keyword arguments</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.LSS" href="#QuantEcon.LSS"><code>QuantEcon.LSS</code></a> — <span class="docstring-category">Type</span>.</div><div><p>A type that describes the Gaussian Linear State Space Model of the form:</p><pre><code class="language-none">x_{t+1} = A x_t + C w_{t+1}

    y_t = G x_t</code></pre><p>where {w_t} and {v_t} are independent and standard normal with dimensions k and l respectively.  The initial conditions are mu_0 and Sigma_0 for x_0 ~ N(mu_0, Sigma_0).  When Sigma_0=0, the draw of x_0 is exactly mu_0.</p><p><strong>Fields</strong></p><ul><li><code>A::Matrix</code> Part of the state transition equation.  It should be <code>n x n</code></li><li><code>C::Matrix</code> Part of the state transition equation.  It should be <code>n x m</code></li><li><code>G::Matrix</code> Part of the observation equation.  It should be <code>k x n</code></li><li><code>k::Int</code> Dimension</li><li><code>n::Int</code> Dimension</li><li><code>m::Int</code> Dimension</li><li><code>mu_0::Vector</code> This is the mean of initial draw and is of length <code>n</code></li><li><code>Sigma_0::Matrix</code> This is the variance of the initial draw and is <code>n x n</code> and                     also should be positive definite and symmetric</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.MPFI" href="#QuantEcon.MPFI"><code>QuantEcon.MPFI</code></a> — <span class="docstring-category">Type</span>.</div><div><p>This refers to the Modified Policy Iteration solution algorithm.</p><p><strong>References</strong></p><p>http://quant-econ.net/jl/ddp.html</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.MarkovChain" href="#QuantEcon.MarkovChain"><code>QuantEcon.MarkovChain</code></a> — <span class="docstring-category">Type</span>.</div><div><p>Finite-state discrete-time Markov chain.</p><p>Methods are available that provide useful information such as the stationary distributions, and communication and recurrent classes, and allow simulation of state transitions.</p><p><strong>Fields</strong></p><ul><li><code>p::AbstractMatrix</code> : The transition matrix. Must be square, all elements must be nonnegative, and all rows must sum to unity.</li><li><code>state_values::AbstractVector</code> : Vector containing the values associated with the states.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.MarkovChain-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{Algo<:QuantEcon.DDPAlgorithm,Tval<:Real}}" href="#QuantEcon.MarkovChain-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{Algo<:QuantEcon.DDPAlgorithm,Tval<:Real}}"><code>QuantEcon.MarkovChain</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Returns the controlled Markov chain for a given policy <code>sigma</code>.</p><p><strong>Parameters</strong></p><ul><li><code>ddp::DiscreteDP</code> : Object that contains the model parameters</li><li><code>ddpr::DPSolveResult</code> : Object that contains result variables</li></ul><p><strong>Returns</strong></p><p>mc : MarkovChain      Controlled Markov chain.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.PFI" href="#QuantEcon.PFI"><code>QuantEcon.PFI</code></a> — <span class="docstring-category">Type</span>.</div><div><p>This refers to the Policy Iteration solution algorithm.</p><p><strong>References</strong></p><p>http://quant-econ.net/jl/ddp.html</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.RBLQ" href="#QuantEcon.RBLQ"><code>QuantEcon.RBLQ</code></a> — <span class="docstring-category">Type</span>.</div><div><p>Represents infinite horizon robust LQ control problems of the form</p><pre><code class="language-none">min_{u_t}  sum_t beta^t {x_t&#39; R x_t + u_t&#39; Q u_t }</code></pre><p>subject to</p><pre><code class="language-none">x_{t+1} = A x_t + B u_t + C w_{t+1}</code></pre><p>and with model misspecification parameter theta.</p><p><strong>Fields</strong></p><ul><li><code>Q::Matrix{Float64}</code> :  The cost(payoff) matrix for the controls. See above for more. <code>Q</code> should be k x k and symmetric and positive definite</li><li><code>R::Matrix{Float64}</code> :  The cost(payoff) matrix for the state. See above for more. <code>R</code> should be n x n and symmetric and non-negative definite</li><li><code>A::Matrix{Float64}</code> :  The matrix that corresponds with the state in the state space system. <code>A</code> should be n x n</li><li><code>B::Matrix{Float64}</code> :  The matrix that corresponds with the control in the state space system.  <code>B</code> should be n x k</li><li><code>C::Matrix{Float64}</code> :  The matrix that corresponds with the random process in the state space system. <code>C</code> should be n x j</li><li><code>beta::Real</code> : The discount factor in the robust control problem</li><li><code>theta::Real</code> The robustness factor in the robust control problem</li><li><code>k, n, j::Int</code> : Dimensions of input matrices</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.VFI" href="#QuantEcon.VFI"><code>QuantEcon.VFI</code></a> — <span class="docstring-category">Type</span>.</div><div><p>This refers to the Value Iteration solution algorithm.</p><p><strong>References</strong></p><p>http://quant-econ.net/jl/ddp.html</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="LightGraphs.period-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}}}" href="#LightGraphs.period-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}}}"><code>LightGraphs.period</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Return the period of the Markov chain <code>mc</code>.</p><p><strong>Arguments</strong></p><ul><li><code>mc::MarkovChain</code> : MarkovChain instance.</li></ul><p><strong>Returns</strong></p><ul><li><code>::Int</code> : Period of <code>mc</code>.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.F_to_K-Tuple{QuantEcon.RBLQ,Array{T,2}}" href="#QuantEcon.F_to_K-Tuple{QuantEcon.RBLQ,Array{T,2}}"><code>QuantEcon.F_to_K</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Compute agent 2&#39;s best cost-minimizing response <code>K</code>, given <code>F</code>.</p><p><strong>Arguments</strong></p><ul><li><code>rlq::RBLQ</code>: Instance of <code>RBLQ</code> type</li><li><code>F::Matrix{Float64}</code>: A k x n array representing agent 1&#39;s policy</li></ul><p><strong>Returns</strong></p><ul><li><code>K::Matrix{Float64}</code> : Agent&#39;s best cost minimizing response corresponding to <code>F</code></li><li><code>P::Matrix{Float64}</code> : The value function corresponding to <code>F</code></li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.K_to_F-Tuple{QuantEcon.RBLQ,Array{T,2}}" href="#QuantEcon.K_to_F-Tuple{QuantEcon.RBLQ,Array{T,2}}"><code>QuantEcon.K_to_F</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Compute agent 1&#39;s best cost-minimizing response <code>K</code>, given <code>F</code>.</p><p><strong>Arguments</strong></p><ul><li><code>rlq::RBLQ</code>: Instance of <code>RBLQ</code> type</li><li><code>K::Matrix{Float64}</code>: A k x n array representing the worst case matrix</li></ul><p><strong>Returns</strong></p><ul><li><code>F::Matrix{Float64}</code> : Agent&#39;s best cost minimizing response corresponding to <code>K</code></li><li><code>P::Matrix{Float64}</code> : The value function corresponding to <code>K</code></li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.RQ_sigma-Tuple{QuantEcon.DiscreteDP{T,3,2,Tbeta,Tind},Array{T<:Integer,N}}" href="#QuantEcon.RQ_sigma-Tuple{QuantEcon.DiscreteDP{T,3,2,Tbeta,Tind},Array{T<:Integer,N}}"><code>QuantEcon.RQ_sigma</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Given a policy <code>sigma</code>, return the reward vector <code>R_sigma</code> and the transition probability matrix <code>Q_sigma</code>.</p><p><strong>Parameters</strong></p><ul><li><code>ddp::DiscreteDP</code> : Object that contains the model parameters</li><li><code>sigma::Vector{Int}</code>: policy rule vector</li></ul><p><strong>Returns</strong></p><ul><li><code>R_sigma::Array{Float64}</code>: Reward vector for <code>sigma</code>, of length n.</li></ul><ul><li><code>Q_sigma::Array{Float64}</code>: Transition probability matrix for <code>sigma</code>,   of shape (n, n).</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.RQ_sigma-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{Algo<:QuantEcon.DDPAlgorithm,Tval<:Real}}" href="#QuantEcon.RQ_sigma-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{Algo<:QuantEcon.DDPAlgorithm,Tval<:Real}}"><code>QuantEcon.RQ_sigma</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Method of <code>RQ_sigma</code> that extracts sigma from a <code>DPSolveResult</code></p><p>See other docstring for details</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.ar_periodogram" href="#QuantEcon.ar_periodogram"><code>QuantEcon.ar_periodogram</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Compute periodogram from data <code>x</code>, using prewhitening, smoothing and recoloring. The data is fitted to an AR(1) model for prewhitening, and the residuals are used to compute a first-pass periodogram with smoothing.  The fitted coefficients are then used for recoloring.</p><p><strong>Arguments</strong></p><ul><li><code>x::Array</code>: An array containing the data to smooth</li><li><code>window_len::Int(7)</code>: An odd integer giving the length of the window</li><li><code>window::AbstractString(&quot;hanning&quot;)</code>: A string giving the window type. Possible values are <code>flat</code>, <code>hanning</code>, <code>hamming</code>, <code>bartlett</code>, or <code>blackman</code></li></ul><p><strong>Returns</strong></p><ul><li><code>w::Array{Float64}</code>: Fourier frequencies at which the periodogram is evaluated</li><li><code>I_w::Array{Float64}</code>: The periodogram at frequences <code>w</code></li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.autocovariance-Tuple{QuantEcon.ARMA}" href="#QuantEcon.autocovariance-Tuple{QuantEcon.ARMA}"><code>QuantEcon.autocovariance</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Compute the autocovariance function from the ARMA parameters over the integers range(num_autocov) using the spectral density and the inverse Fourier transform.</p><p><strong>Arguments</strong></p><ul><li><code>arma::ARMA</code>: Instance of <code>ARMA</code> type</li><li><code>;num_autocov::Integer(16)</code> : The number of autocovariances to calculate</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.b_operator-Tuple{QuantEcon.RBLQ,Array{T,2}}" href="#QuantEcon.b_operator-Tuple{QuantEcon.RBLQ,Array{T,2}}"><code>QuantEcon.b_operator</code></a> — <span class="docstring-category">Method</span>.</div><div><p>The D operator, mapping P into</p><pre><code class="language-none">B(P) := R - beta^2 A&#39;PB(Q + beta B&#39;PB)^{-1}B&#39;PA + beta A&#39;PA</code></pre><p>and also returning</p><pre><code class="language-none">F := (Q + beta B&#39;PB)^{-1} beta B&#39;PA</code></pre><p><strong>Arguments</strong></p><ul><li><code>rlq::RBLQ</code>: Instance of <code>RBLQ</code> type</li><li><code>P::Matrix{Float64}</code> : <code>size</code> is n x n</li></ul><p><strong>Returns</strong></p><ul><li><code>F::Matrix{Float64}</code> : The F matrix as defined above</li><li><code>new_p::Matrix{Float64}</code> : The matrix P after applying the B operator</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.bellman_operator!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},Array{T,1},Array{T,1},Array{T,1}}" href="#QuantEcon.bellman_operator!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},Array{T,1},Array{T,1},Array{T,1}}"><code>QuantEcon.bellman_operator!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>The Bellman operator, which computes and returns the updated value function Tv for a value function v.</p><p><strong>Parameters</strong></p><ul><li><code>ddp::DiscreteDP</code> : Object that contains the model parameters</li><li><code>v::Vector{T&lt;:AbstractFloat}</code>: The current guess of the value function</li><li><code>Tv::Vector{T&lt;:AbstractFloat}</code>: A buffer array to hold the updated value   function. Initial value not used and will be overwritten</li><li><code>sigma::Vector</code>: A buffer array to hold the policy function. Initial   values not used and will be overwritten</li></ul><p><strong>Returns</strong></p><ul><li><code>Tv::Vector</code> : Updated value function vector</li><li><code>sigma::Vector</code> : Updated policiy function vector</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.bellman_operator!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},Array{T<:AbstractFloat,1},Array{T,1}}" href="#QuantEcon.bellman_operator!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},Array{T<:AbstractFloat,1},Array{T,1}}"><code>QuantEcon.bellman_operator!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>The Bellman operator, which computes and returns the updated value function Tv for a given value function v.</p><p>This function will fill the input <code>v</code> with <code>Tv</code> and the input <code>sigma</code> with the corresponding policy rule</p><p><strong>Parameters</strong></p><ul><li><code>ddp::DiscreteDP</code>: The ddp model</li><li><code>v::Vector{T&lt;:AbstractFloat}</code>: The current guess of the value function. This   array will be overwritten</li><li><code>sigma::Vector</code>: A buffer array to hold the policy function. Initial   values not used and will be overwritten</li></ul><p><strong>Returns</strong></p><ul><li><code>Tv::Vector</code>: Updated value function vector</li><li><code>sigma::Vector{T&lt;:Integer}</code>: Policy rule</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.bellman_operator!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{Algo<:QuantEcon.DDPAlgorithm,Tval<:Real}}" href="#QuantEcon.bellman_operator!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{Algo<:QuantEcon.DDPAlgorithm,Tval<:Real}}"><code>QuantEcon.bellman_operator!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Apply the Bellman operator using <code>v=ddpr.v</code>, <code>Tv=ddpr.Tv</code>, and <code>sigma=ddpr.sigma</code></p><p><strong>Notes</strong></p><p>Updates <code>ddpr.Tv</code> and <code>ddpr.sigma</code> inplace</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.bellman_operator-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},Array{T,1}}" href="#QuantEcon.bellman_operator-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},Array{T,1}}"><code>QuantEcon.bellman_operator</code></a> — <span class="docstring-category">Method</span>.</div><div><p>The Bellman operator, which computes and returns the updated value function Tv for a given value function v.</p><p><strong>Parameters</strong></p><ul><li><code>ddp::DiscreteDP</code>: The ddp model</li><li><code>v::Vector</code>: The current guess of the value function</li></ul><p><strong>Returns</strong></p><ul><li><code>Tv::Vector</code> : Updated value function vector</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.ckron" href="#QuantEcon.ckron"><code>QuantEcon.ckron</code></a> — <span class="docstring-category">Function</span>.</div><div><p><code>ckron(arrays::AbstractArray...)</code></p><p>Repeatedly apply kronecker products to the arrays. Equilvalent to <code>reduce(kron, arrays)</code></p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.communication_classes-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}}}" href="#QuantEcon.communication_classes-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}}}"><code>QuantEcon.communication_classes</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Find the communication classes of the Markov chain <code>mc</code>.</p><p><strong>Arguments</strong></p><ul><li><code>mc::MarkovChain</code> : MarkovChain instance.</li></ul><p><strong>Returns</strong></p><ul><li><code>::Vector{Vector{Int}}</code> : Vector of vectors that describe the communication classes of <code>mc</code>.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.compute_deterministic_entropy-Tuple{QuantEcon.RBLQ,Any,Any,Any}" href="#QuantEcon.compute_deterministic_entropy-Tuple{QuantEcon.RBLQ,Any,Any,Any}"><code>QuantEcon.compute_deterministic_entropy</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Given <code>K</code> and <code>F</code>, compute the value of deterministic entropy, which is sum_t beta^t x_t&#39; K&#39;K x_t with x_{t+1} = (A - BF + CK) x_t.</p><p><strong>Arguments</strong></p><ul><li><code>rlq::RBLQ</code>: Instance of <code>RBLQ</code> type</li><li><code>F::Matrix{Float64}</code> The policy function, a k x n array</li><li><code>K::Matrix{Float64}</code> The worst case matrix, a j x n array</li><li><code>x0::Vector{Float64}</code> : The initial condition for state</li></ul><p><strong>Returns</strong></p><ul><li><code>e::Float64</code> The deterministic entropy</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.compute_fixed_point-Tuple{Function,TV}" href="#QuantEcon.compute_fixed_point-Tuple{Function,TV}"><code>QuantEcon.compute_fixed_point</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Repeatedly apply a function to search for a fixed point</p><p>Approximates <code>T^∞ v</code>, where <code>T</code> is an operator (function) and <code>v</code> is an initial guess for the fixed point. Will terminate either when <code>T^{k+1}(v) - T^k v &lt; err_tol</code> or <code>max_iter</code> iterations has been exceeded.</p><p>Provided that <code>T</code> is a contraction mapping or similar,  the return value will be an approximation to the fixed point of <code>T</code>.</p><p><strong>Arguments</strong></p><ul><li><code>T</code>: A function representing the operator <code>T</code></li><li><code>v::TV</code>: The initial condition. An object of type <code>TV</code></li><li><code>;err_tol(1e-3)</code>: Stopping tolerance for iterations</li><li><code>;max_iter(50)</code>: Maximum number of iterations</li><li><code>;verbose(true)</code>: Whether or not to print status updates to the user</li><li><code>;print_skip(10)</code> : if <code>verbose</code> is true, how many iterations to apply between   print messages</li></ul><p><strong>Returns</strong></p><hr/><ul><li>&#39;::TV&#39;: The fixed point of the operator <code>T</code>. Has type <code>TV</code></li></ul><p><strong>Example</strong></p><pre><code class="language-julia">using QuantEcon
T(x, μ) = 4.0 * μ * x * (1.0 - x)
x_star = compute_fixed_point(x-&gt;T(x, 0.3), 0.4)  # (4μ - 1)/(4μ)</code></pre></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.compute_greedy!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{Algo<:QuantEcon.DDPAlgorithm,Tval<:Real}}" href="#QuantEcon.compute_greedy!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{Algo<:QuantEcon.DDPAlgorithm,Tval<:Real}}"><code>QuantEcon.compute_greedy!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Compute the v-greedy policy</p><p><strong>Parameters</strong></p><ul><li><code>ddp::DiscreteDP</code> : Object that contains the model parameters</li><li><code>ddpr::DPSolveResult</code> : Object that contains result variables</li></ul><p><strong>Returns</strong></p><ul><li><code>sigma::Vector{Int}</code> : Array containing <code>v</code>-greedy policy rule</li></ul><p><strong>Notes</strong></p><p>modifies ddpr.sigma and ddpr.Tv in place</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.compute_greedy-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},Array{TV<:Real,1}}" href="#QuantEcon.compute_greedy-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},Array{TV<:Real,1}}"><code>QuantEcon.compute_greedy</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Compute the v-greedy policy.</p><p><strong>Arguments</strong></p><ul><li><code>v::Vector</code> Value function vector of length <code>n</code></li><li><code>ddp::DiscreteDP</code> Object that contains the model parameters</li></ul><p><strong>Returns</strong></p><ul><li><code>sigma:: v-greedy policy vector, of length `n</code></li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.compute_sequence" href="#QuantEcon.compute_sequence"><code>QuantEcon.compute_sequence</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Compute and return the optimal state and control sequence, assuming innovation N(0,1)</p><p><strong>Arguments</strong></p><ul><li><code>lq::LQ</code> : instance of <code>LQ</code> type</li><li><code>x0::ScalarOrArray</code>: initial state</li><li><code>ts_length::Integer(100)</code> : maximum number of periods for which to return process. If <code>lq</code> instance is finite horizon type, the sequenes are returned only for <code>min(ts_length, lq.capT)</code></li></ul><p><strong>Returns</strong></p><ul><li><code>x_path::Matrix{Float64}</code> : An n x T+1 matrix, where the t-th column represents <code>x_t</code></li><li><code>u_path::Matrix{Float64}</code> : A k x T matrix, where the t-th column represents <code>u_t</code></li><li><code>w_path::Matrix{Float64}</code> : A n x T+1 matrix, where the t-th column represents <code>lq.C*N(0,1)</code></li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.d_operator-Tuple{QuantEcon.RBLQ,Array{T,2}}" href="#QuantEcon.d_operator-Tuple{QuantEcon.RBLQ,Array{T,2}}"><code>QuantEcon.d_operator</code></a> — <span class="docstring-category">Method</span>.</div><div><p>The D operator, mapping P into</p><pre><code class="language-none">D(P) := P + PC(theta I - C&#39;PC)^{-1} C&#39;P.</code></pre><p><strong>Arguments</strong></p><ul><li><code>rlq::RBLQ</code>: Instance of <code>RBLQ</code> type</li><li><code>P::Matrix{Float64}</code> : <code>size</code> is n x n</li></ul><p><strong>Returns</strong></p><ul><li><code>dP::Matrix{Float64}</code> : The matrix P after applying the D operator</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.do_quad-Tuple{Function,Array{T,N},Array{T,1},Vararg{Any}}" href="#QuantEcon.do_quad-Tuple{Function,Array{T,N},Array{T,1},Vararg{Any}}"><code>QuantEcon.do_quad</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Approximate the integral of <code>f</code>, given quadrature <code>nodes</code> and <code>weights</code></p><p><strong>Arguments</strong></p><ul><li><code>f::Function</code>: A callable function that is to be approximated over the domain spanned by <code>nodes</code>.</li><li><code>nodes::Array</code>: Quadrature nodes</li><li><code>weights::Array</code>: Quadrature nodes</li><li><code>args...(Void)</code>: additional positional arguments to pass to <code>f</code></li><li><code>;kwargs...(Void)</code>: additional keyword arguments to pass to <code>f</code></li></ul><p><strong>Returns</strong></p><ul><li><code>out::Float64</code> : The scalar that approximates integral of <code>f</code> on the hypercube formed by <code>[a, b]</code></li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.draw-Tuple{QuantEcon.DiscreteRV{TV1<:AbstractArray{T,1},TV2<:AbstractArray{T,1}},Int64}" href="#QuantEcon.draw-Tuple{QuantEcon.DiscreteRV{TV1<:AbstractArray{T,1},TV2<:AbstractArray{T,1}},Int64}"><code>QuantEcon.draw</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Make multiple draws from the discrete distribution represented by a <code>DiscreteRV</code> instance</p><p><strong>Arguments</strong></p><ul><li><code>d::DiscreteRV</code>: The <code>DiscreteRV</code> type representing the distribution</li><li><code>k::Int</code>:</li></ul><p><strong>Returns</strong></p><ul><li><code>out::Vector{Int}</code>: <code>k</code> draws from <code>d</code></li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.draw-Tuple{QuantEcon.DiscreteRV{TV1<:AbstractArray{T,1},TV2<:AbstractArray{T,1}}}" href="#QuantEcon.draw-Tuple{QuantEcon.DiscreteRV{TV1<:AbstractArray{T,1},TV2<:AbstractArray{T,1}}}"><code>QuantEcon.draw</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Make a single draw from the discrete distribution</p><p><strong>Arguments</strong></p><ul><li><code>d::DiscreteRV</code>: The <code>DiscreteRV</code> type represetning the distribution</li></ul><p><strong>Returns</strong></p><ul><li><code>out::Int</code>: One draw from the discrete distribution</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.ecdf" href="#QuantEcon.ecdf"><code>QuantEcon.ecdf</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Evaluate the empirical cdf at one or more points</p><p><strong>Arguments</strong></p><ul><li><code>e::ECDF</code>: The <code>ECDF</code> instance</li><li><code>x::Union{Real, Array}</code>: The point(s) at which to evaluate the ECDF</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.evaluate_F-Tuple{QuantEcon.RBLQ,Array{T,2}}" href="#QuantEcon.evaluate_F-Tuple{QuantEcon.RBLQ,Array{T,2}}"><code>QuantEcon.evaluate_F</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Given a fixed policy <code>F</code>, with the interpretation u = -F x, this function computes the matrix P_F and constant d_F associated with discounted cost J_F(x) = x&#39; P_F x + d_F.</p><p><strong>Arguments</strong></p><ul><li><code>rlq::RBLQ</code>: Instance of <code>RBLQ</code> type</li><li><code>F::Matrix{Float64}</code> :  The policy function, a k x n array</li></ul><p><strong>Returns</strong></p><ul><li><code>P_F::Matrix{Float64}</code> : Matrix for discounted cost</li><li><code>d_F::Float64</code> : Constant for discounted cost</li><li><code>K_F::Matrix{Float64}</code> : Worst case policy</li><li><code>O_F::Matrix{Float64}</code> : Matrix for discounted entropy</li><li><code>o_F::Float64</code> : Constant for discounted entropy</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.evaluate_policy-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},Array{T<:Integer,1}}" href="#QuantEcon.evaluate_policy-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},Array{T<:Integer,1}}"><code>QuantEcon.evaluate_policy</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Compute the value of a policy.</p><p><strong>Parameters</strong></p><ul><li><code>ddp::DiscreteDP</code> : Object that contains the model parameters</li><li><code>sigma::Vector{T&lt;:Integer}</code> : Policy rule vector</li></ul><p><strong>Returns</strong></p><ul><li><code>v_sigma::Array{Float64}</code> : Value vector of <code>sigma</code>, of length n.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.evaluate_policy-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{Algo<:QuantEcon.DDPAlgorithm,Tval<:Real}}" href="#QuantEcon.evaluate_policy-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{Algo<:QuantEcon.DDPAlgorithm,Tval<:Real}}"><code>QuantEcon.evaluate_policy</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Method of <code>evaluate_policy</code> that extracts sigma from a <code>DPSolveResult</code></p><p>See other docstring for details</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.filtered_to_forecast!-Tuple{QuantEcon.Kalman}" href="#QuantEcon.filtered_to_forecast!-Tuple{QuantEcon.Kalman}"><code>QuantEcon.filtered_to_forecast!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Updates the moments of the time t filtering distribution to the moments of the predictive distribution, which becomes the time t+1 prior</p><p><strong>Arguments</strong></p><ul><li><code>k::Kalman</code> An instance of the Kalman filter</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.gridmake" href="#QuantEcon.gridmake"><code>QuantEcon.gridmake</code></a> — <span class="docstring-category">Function</span>.</div><div><p><code>gridmake(arrays::AbstractVector...)</code></p><p>Expand one or more vectors into a matrix where rows span the cartesian product of combinations of the input vectors. Each input array will correspond to one column of the output matrix. The first array varies the fastest (see example)</p><p><strong>Example</strong></p><pre><code class="language-jlcon">julia&gt; x = [1, 2, 3]; y = [10, 20]; z = [100, 200];

julia&gt; gridmake(x, y, z)
12x3 Array{Int64,2}:
 1  10  100
 2  10  100
 3  10  100
 1  20  100
 2  20  100
 3  20  100
 1  10  200
 2  10  200
 3  10  200
 1  20  200
 2  20  200
 3  20  200</code></pre></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.gridmake!-Tuple{Any,Vararg{AbstractArray{T,1}}}" href="#QuantEcon.gridmake!-Tuple{Any,Vararg{AbstractArray{T,1}}}"><code>QuantEcon.gridmake!</code></a> — <span class="docstring-category">Method</span>.</div><div><p><code>gridmake!(out::AbstractMatrix, arrays::AbstractVector...)</code></p><p>Like <code>gridmake</code>, but fills a pre-populated array. <code>out</code> must have size <code>prod(map(length, arrays), length(arrays))</code></p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.gth_solve-Tuple{Array{T<:Real,2}}" href="#QuantEcon.gth_solve-Tuple{Array{T<:Real,2}}"><code>QuantEcon.gth_solve</code></a> — <span class="docstring-category">Method</span>.</div><div><p>This routine computes the stationary distribution of an irreducible Markov transition matrix (stochastic matrix) or transition rate matrix (generator matrix) <code>A</code>.</p><p>More generally, given a Metzler matrix (square matrix whose off-diagonal entries are all nonnegative) <code>A</code>, this routine solves for a nonzero solution <code>x</code> to <code>x (A - D) = 0</code>, where <code>D</code> is the diagonal matrix for which the rows of <code>A - D</code> sum to zero (i.e., <code>D_{ii} = sum_j A_{ij}</code> for all <code>i</code>). One (and only one, up to normalization) nonzero solution exists corresponding to each reccurent class of <code>A</code>, and in particular, if <code>A</code> is irreducible, there is a unique solution; when there are more than one solution, the routine returns the solution that contains in its support the first index <code>i</code> such that no path connects <code>i</code> to any index larger than <code>i</code>. The solution is normalized so that its 1-norm equals one. This routine implements the Grassmann-Taksar-Heyman (GTH) algorithm (Grassmann, Taksar, and Heyman 1985), a numerically stable variant of Gaussian elimination, where only the off-diagonal entries of <code>A</code> are used as the input data. For a nice exposition of the algorithm, see Stewart (2009), Chapter 10.</p><p><strong>Arguments</strong></p><ul><li><code>A::Matrix{T}</code> : Stochastic matrix or generator matrix. Must be of shape n x   n.</li></ul><p><strong>Returns</strong></p><ul><li><code>x::Vector{T}</code> : Stationary distribution of <code>A</code>.</li></ul><p><strong>References</strong></p><ul><li>W. K. Grassmann, M. I. Taksar and D. P. Heyman, &quot;Regenerative Analysis and Steady State Distributions for Markov Chains, &quot; Operations Research (1985), 1107-1116.</li><li>W. J. Stewart, Probability, Markov Chains, Queues, and Simulation, Princeton University Press, 2009.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.impulse_response-Tuple{QuantEcon.ARMA}" href="#QuantEcon.impulse_response-Tuple{QuantEcon.ARMA}"><code>QuantEcon.impulse_response</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Get the impulse response corresponding to our model.</p><p><strong>Arguments</strong></p><ul><li><code>arma::ARMA</code>: Instance of <code>ARMA</code> type</li><li><code>;impulse_length::Integer(30)</code>: Length of horizon for calucluating impulse reponse. Must be at least as long as the <code>p</code> fields of <code>arma</code></li></ul><p><strong>Returns</strong></p><ul><li><code>psi::Vector{Float64}</code>: <code>psi[j]</code> is the response at lag j of the impulse response. We take psi[1] as unity.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.is_aperiodic-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}}}" href="#QuantEcon.is_aperiodic-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}}}"><code>QuantEcon.is_aperiodic</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Indicate whether the Markov chain <code>mc</code> is aperiodic.</p><p><strong>Arguments</strong></p><ul><li><code>mc::MarkovChain</code> : MarkovChain instance.</li></ul><p><strong>Returns</strong></p><ul><li><code>::Bool</code></li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.is_irreducible-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}}}" href="#QuantEcon.is_irreducible-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}}}"><code>QuantEcon.is_irreducible</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Indicate whether the Markov chain <code>mc</code> is irreducible.</p><p><strong>Arguments</strong></p><ul><li><code>mc::MarkovChain</code> : MarkovChain instance.</li></ul><p><strong>Returns</strong></p><ul><li><code>::Bool</code></li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.lae_est-Tuple{QuantEcon.LAE,AbstractArray{T,N}}" href="#QuantEcon.lae_est-Tuple{QuantEcon.LAE,AbstractArray{T,N}}"><code>QuantEcon.lae_est</code></a> — <span class="docstring-category">Method</span>.</div><div><p>A vectorized function that returns the value of the look ahead estimate at the values in the array y.</p><p><strong>Arguments</strong></p><ul><li><code>l::LAE</code>: Instance of <code>LAE</code> type</li><li><code>y::Array</code>: Array that becomes the <code>y</code> in <code>l.p(l.x, y)</code></li></ul><p><strong>Returns</strong></p><ul><li><code>psi_vals::Vector</code>: Density at <code>(x, y)</code></li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.m_quadratic_sum-Tuple{Array{T,2},Array{T,2}}" href="#QuantEcon.m_quadratic_sum-Tuple{Array{T,2},Array{T,2}}"><code>QuantEcon.m_quadratic_sum</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Computes the quadratic sum</p><pre><code class="language-none">V = sum_{j=0}^{infty} A^j B A^{j&#39;}</code></pre><p>V is computed by solving the corresponding discrete lyapunov equation using the doubling algorithm.  See the documentation of <code>solve_discrete_lyapunov</code> for more information.</p><p><strong>Arguments</strong></p><ul><li><code>A::Matrix{Float64}</code> : An n x n matrix as described above.  We assume in order for convergence that the eigenvalues of A have moduli bounded by unity</li><li><code>B::Matrix{Float64}</code> : An n x n matrix as described above.  We assume in order for convergence that the eigenvalues of B have moduli bounded by unity</li><li><code>max_it::Int(50)</code> : Maximum number of iterations</li></ul><p><strong>Returns</strong></p><ul><li><code>gamma1::Matrix{Float64}</code> : Represents the value V</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.moment_sequence-Tuple{QuantEcon.LSS}" href="#QuantEcon.moment_sequence-Tuple{QuantEcon.LSS}"><code>QuantEcon.moment_sequence</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Create a generator to calculate the population mean and variance-convariance matrix for both x_t and y_t, starting at the initial condition (self.mu_0, self.Sigma_0).  Each iteration produces a 4-tuple of items (mu_x, mu_y, Sigma_x, Sigma_y) for the next period.</p><p><strong>Arguments</strong></p><ul><li><code>lss::LSS</code> An instance of the Gaussian linear state space model</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.n_states-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}}}" href="#QuantEcon.n_states-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}}}"><code>QuantEcon.n_states</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Number of states in the Markov chain <code>mc</code></p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.nnash-Tuple{Any,Any,Any,Any,Any,Any,Any,Any,Any,Any,Any,Any,Any}" href="#QuantEcon.nnash-Tuple{Any,Any,Any,Any,Any,Any,Any,Any,Any,Any,Any,Any,Any}"><code>QuantEcon.nnash</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Compute the limit of a Nash linear quadratic dynamic game.</p><p>Player <code>i</code> minimizes</p><pre><code class="language-none">sum_{t=1}^{inf}(x_t&#39; r_i x_t + 2 x_t&#39; w_i
u_{it} +u_{it}&#39; q_i u_{it} + u_{jt}&#39; s_i u_{jt} + 2 u_{jt}&#39;
m_i u_{it})</code></pre><p>subject to the law of motion</p><pre><code class="language-none">x_{t+1} = A x_t + b_1 u_{1t} + b_2 u_{2t}</code></pre><p>and a perceived control law :math:<code>u_j(t) = - f_j x_t</code> for the other player.</p><p>The solution computed in this routine is the <code>f_i</code> and <code>p_i</code> of the associated double optimal linear regulator problem.</p><p><strong>Arguments</strong></p><ul><li><code>A</code> : Corresponds to the above equation, should be of size (n, n)</li><li><code>B1</code> : As above, size (n, k_1)</li><li><code>B2</code> : As above, size (n, k_2)</li><li><code>R1</code> : As above, size (n, n)</li><li><code>R2</code> : As above, size (n, n)</li><li><code>Q1</code> : As above, size (k_1, k_1)</li><li><code>Q2</code> : As above, size (k_2, k_2)</li><li><code>S1</code> : As above, size (k_1, k_1)</li><li><code>S2</code> : As above, size (k_2, k_2)</li><li><code>W1</code> : As above, size (n, k_1)</li><li><code>W2</code> : As above, size (n, k_2)</li><li><code>M1</code> : As above, size (k_2, k_1)</li><li><code>M2</code> : As above, size (k_1, k_2)</li><li><code>;beta::Float64(1.0)</code> Discount rate</li><li><code>;tol::Float64(1e-8)</code> : Tolerance level for convergence</li><li><code>;max_iter::Int(1000)</code> : Maximum number of iterations allowed</li></ul><p><strong>Returns</strong></p><ul><li><code>F1::Matrix{Float64}</code>: (k_1, n) matrix representing feedback law for agent 1</li><li><code>F2::Matrix{Float64}</code>: (k_2, n) matrix representing feedback law for agent 2</li><li><code>P1::Matrix{Float64}</code>: (n, n) matrix representing the steady-state solution to the associated discrete matrix ticcati equation for agent 1</li><li><code>P2::Matrix{Float64}</code>: (n, n) matrix representing the steady-state solution to the associated discrete matrix riccati equation for agent 2</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.periodogram" href="#QuantEcon.periodogram"><code>QuantEcon.periodogram</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Computes the periodogram</p><pre><code class="language-none">I(w) = (1 / n) | sum_{t=0}^{n-1} x_t e^{itw} |^2</code></pre><p>at the Fourier frequences w_j := 2 pi j / n, j = 0, ..., n - 1, using the fast Fourier transform.  Only the frequences w_j in [0, pi] and corresponding values I(w_j) are returned.  If a window type is given then smoothing is performed.</p><p><strong>Arguments</strong></p><ul><li><code>x::Array</code>: An array containing the data to smooth</li><li><code>window_len::Int(7)</code>: An odd integer giving the length of the window</li><li><code>window::AbstractString(&quot;hanning&quot;)</code>: A string giving the window type. Possible values are <code>flat</code>, <code>hanning</code>, <code>hamming</code>, <code>bartlett</code>, or <code>blackman</code></li></ul><p><strong>Returns</strong></p><ul><li><code>w::Array{Float64}</code>: Fourier frequencies at which the periodogram is evaluated</li><li><code>I_w::Array{Float64}</code>: The periodogram at frequences <code>w</code></li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.prior_to_filtered!-Tuple{QuantEcon.Kalman,Any}" href="#QuantEcon.prior_to_filtered!-Tuple{QuantEcon.Kalman,Any}"><code>QuantEcon.prior_to_filtered!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Updates the moments (cur_x_hat, cur_sigma) of the time t prior to the time t filtering distribution, using current measurement y_t. The updates are according to     x_{hat}^F = x_{hat} + Sigma G&#39; (G Sigma G&#39; + R)^{-1}                     (y - G x_{hat})     Sigma^F = Sigma - Sigma G&#39; (G Sigma G&#39; + R)^{-1} G                 Sigma</p><p><strong>Arguments</strong></p><ul><li><code>k::Kalman</code> An instance of the Kalman filter</li><li><code>y</code> The current measurement</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.qnwbeta-Tuple{Int64,Real,Real}" href="#QuantEcon.qnwbeta-Tuple{Int64,Real,Real}"><code>QuantEcon.qnwbeta</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Computes nodes and weights for beta distribution</p><p><strong>Arguments</strong></p><ul><li><code>n::Union{Int, Vector{Int}}</code> : Number of desired nodes along each dimension</li><li><code>a::Union{Real, Vector{Real}}</code> : First parameter of the beta distribution, along each dimension</li><li><code>b::Union{Real, Vector{Real}}</code> : Second parameter of the beta distribution, along each dimension</li></ul><p><strong>Returns</strong></p><ul><li><code>nodes::Array{Float64}</code> : An array of quadrature nodes</li><li><code>weights::Array{Float64}</code> : An array of corresponding quadrature weights</li></ul><p><strong>Notes</strong></p><p>If any of the parameters to this function are scalars while others are <code>Vector</code>s of length <code>n</code>, the the scalar parameter is repeated <code>n</code> times.</p><p><strong>References</strong></p><p>Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and Finance, MIT Press, 2002.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.qnwcheb-Tuple{Int64,Real,Real}" href="#QuantEcon.qnwcheb-Tuple{Int64,Real,Real}"><code>QuantEcon.qnwcheb</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Computes multivariate Guass-Checbychev quadrature nodes and weights.</p><p><strong>Arguments</strong></p><ul><li><code>n::Union{Int, Vector{Int}}</code> : Number of desired nodes along each dimension</li><li><code>a::Union{Real, Vector{Real}}</code> : Lower endpoint along each dimension</li><li><code>b::Union{Real, Vector{Real}}</code> : Upper endpoint along each dimension</li></ul><p><strong>Returns</strong></p><ul><li><code>nodes::Array{Float64}</code> : An array of quadrature nodes</li><li><code>weights::Array{Float64}</code> : An array of corresponding quadrature weights</li></ul><p><strong>Notes</strong></p><p>If any of the parameters to this function are scalars while others are <code>Vector</code>s of length <code>n</code>, the the scalar parameter is repeated <code>n</code> times.</p><p><strong>References</strong></p><p>Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and Finance, MIT Press, 2002.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.qnwequi" href="#QuantEcon.qnwequi"><code>QuantEcon.qnwequi</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Generates equidistributed sequences with property that averages value of integrable function evaluated over the sequence converges to the integral as n goes to infinity.</p><p><strong>Arguments</strong></p><ul><li><code>n::Union{Int, Vector{Int}}</code> : Number of desired nodes along each dimension</li><li><code>a::Union{Real, Vector{Real}}</code> : Lower endpoint along each dimension</li><li><code>b::Union{Real, Vector{Real}}</code> : Upper endpoint along each dimension</li><li><code>kind::AbstractString(&quot;N&quot;)</code>: One of the following:     - N - Neiderreiter (default)     - W - Weyl     - H - Haber     - R - pseudo Random</li></ul><p><strong>Returns</strong></p><ul><li><code>nodes::Array{Float64}</code> : An array of quadrature nodes</li><li><code>weights::Array{Float64}</code> : An array of corresponding quadrature weights</li></ul><p><strong>Notes</strong></p><p>If any of the parameters to this function are scalars while others are <code>Vector</code>s of length <code>n</code>, the the scalar parameter is repeated <code>n</code> times.</p><p><strong>References</strong></p><p>Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and Finance, MIT Press, 2002.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.qnwgamma" href="#QuantEcon.qnwgamma"><code>QuantEcon.qnwgamma</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Computes nodes and weights for beta distribution</p><p><strong>Arguments</strong></p><ul><li><code>n::Union{Int, Vector{Int}}</code> : Number of desired nodes along each dimension</li><li><code>a::Union{Real, Vector{Real}}</code> : First parameter of the gamma distribution, along each dimension</li><li><code>b::Union{Real, Vector{Real}}</code> : Second parameter of the gamma distribution, along each dimension</li></ul><p><strong>Returns</strong></p><ul><li><code>nodes::Array{Float64}</code> : An array of quadrature nodes</li><li><code>weights::Array{Float64}</code> : An array of corresponding quadrature weights</li></ul><p><strong>Notes</strong></p><p>If any of the parameters to this function are scalars while others are <code>Vector</code>s of length <code>n</code>, the the scalar parameter is repeated <code>n</code> times.</p><p><strong>References</strong></p><p>Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and Finance, MIT Press, 2002.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.qnwlege-Tuple{Int64,Real,Real}" href="#QuantEcon.qnwlege-Tuple{Int64,Real,Real}"><code>QuantEcon.qnwlege</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Computes multivariate Guass-Legendre  quadrature nodes and weights.</p><p><strong>Arguments</strong></p><ul><li><code>n::Union{Int, Vector{Int}}</code> : Number of desired nodes along each dimension</li><li><code>a::Union{Real, Vector{Real}}</code> : Lower endpoint along each dimension</li><li><code>b::Union{Real, Vector{Real}}</code> : Upper endpoint along each dimension</li></ul><p><strong>Returns</strong></p><ul><li><code>nodes::Array{Float64}</code> : An array of quadrature nodes</li><li><code>weights::Array{Float64}</code> : An array of corresponding quadrature weights</li></ul><p><strong>Notes</strong></p><p>If any of the parameters to this function are scalars while others are <code>Vector</code>s of length <code>n</code>, the the scalar parameter is repeated <code>n</code> times.</p><p><strong>References</strong></p><p>Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and Finance, MIT Press, 2002.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.qnwlogn-Tuple{Any,Any,Any}" href="#QuantEcon.qnwlogn-Tuple{Any,Any,Any}"><code>QuantEcon.qnwlogn</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Computes quadrature nodes and weights for multivariate uniform distribution</p><p><strong>Arguments</strong></p><ul><li><code>n::Union{Int, Vector{Int}}</code> : Number of desired nodes along each dimension</li><li><code>mu::Union{Real, Vector{Real}}</code> : Mean along each dimension</li><li><code>sig2::Union{Real, Vector{Real}, Matrix{Real}}(eye(length(n)))</code> : Covariance structure</li></ul><p><strong>Returns</strong></p><ul><li><code>nodes::Array{Float64}</code> : An array of quadrature nodes</li><li><code>weights::Array{Float64}</code> : An array of corresponding quadrature weights</li></ul><p><strong>Notes</strong></p><p>See also the documentation for <code>qnwnorm</code></p><p><strong>References</strong></p><p>Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and Finance, MIT Press, 2002.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.qnwnorm-Tuple{Int64}" href="#QuantEcon.qnwnorm-Tuple{Int64}"><code>QuantEcon.qnwnorm</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Computes nodes and weights for multivariate normal distribution</p><p><strong>Arguments</strong></p><ul><li><code>n::Union{Int, Vector{Int}}</code> : Number of desired nodes along each dimension</li><li><code>mu::Union{Real, Vector{Real}}</code> : Mean along each dimension</li><li><code>sig2::Union{Real, Vector{Real}, Matrix{Real}}(eye(length(n)))</code> : Covariance structure</li></ul><p><strong>Returns</strong></p><ul><li><code>nodes::Array{Float64}</code> : An array of quadrature nodes</li><li><code>weights::Array{Float64}</code> : An array of corresponding quadrature weights</li></ul><p><strong>Notes</strong></p><p>This function has many methods. I try to describe them here.</p><p><code>n</code> or <code>mu</code> can be a vector or a scalar. If just one is a scalar the other is repeated to match the length of the other. If both are scalars, then the number of repeats is inferred from <code>sig2</code>.</p><p><code>sig2</code> can be a matrix, vector or scalar. If it is a matrix, it is treated as the covariance matrix. If it is a vector, it is considered the diagonal of a diagonal covariance matrix. If it is a scalar it is repeated along the diagonal as many times as necessary, where the number of repeats is determined by the length of either n and/or mu (which ever is a vector).</p><p>If all 3 are scalars, then 1d nodes are computed. <code>mu</code> and <code>sig2</code> are treated as the mean and variance of a 1d normal distribution</p><p><strong>References</strong></p><p>Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and Finance, MIT Press, 2002.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.qnwsimp-Tuple{Int64,Real,Real}" href="#QuantEcon.qnwsimp-Tuple{Int64,Real,Real}"><code>QuantEcon.qnwsimp</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Computes multivariate Simpson quadrature nodes and weights.</p><p><strong>Arguments</strong></p><ul><li><code>n::Union{Int, Vector{Int}}</code> : Number of desired nodes along each dimension</li><li><code>a::Union{Real, Vector{Real}}</code> : Lower endpoint along each dimension</li><li><code>b::Union{Real, Vector{Real}}</code> : Upper endpoint along each dimension</li></ul><p><strong>Returns</strong></p><ul><li><code>nodes::Array{Float64}</code> : An array of quadrature nodes</li><li><code>weights::Array{Float64}</code> : An array of corresponding quadrature weights</li></ul><p><strong>Notes</strong></p><p>If any of the parameters to this function are scalars while others are <code>Vector</code>s of length <code>n</code>, the the scalar parameter is repeated <code>n</code> times.</p><p><strong>References</strong></p><p>Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and Finance, MIT Press, 2002.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.qnwtrap-Tuple{Int64,Real,Real}" href="#QuantEcon.qnwtrap-Tuple{Int64,Real,Real}"><code>QuantEcon.qnwtrap</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Computes multivariate trapezoid quadrature nodes and weights.</p><p><strong>Arguments</strong></p><ul><li><code>n::Union{Int, Vector{Int}}</code> : Number of desired nodes along each dimension</li><li><code>a::Union{Real, Vector{Real}}</code> : Lower endpoint along each dimension</li><li><code>b::Union{Real, Vector{Real}}</code> : Upper endpoint along each dimension</li></ul><p><strong>Returns</strong></p><ul><li><code>nodes::Array{Float64}</code> : An array of quadrature nodes</li><li><code>weights::Array{Float64}</code> : An array of corresponding quadrature weights</li></ul><p><strong>Notes</strong></p><p>If any of the parameters to this function are scalars while others are <code>Vector</code>s of length <code>n</code>, the the scalar parameter is repeated <code>n</code> times.</p><p><strong>References</strong></p><p>Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and Finance, MIT Press, 2002.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.qnwunif-Tuple{Any,Any,Any}" href="#QuantEcon.qnwunif-Tuple{Any,Any,Any}"><code>QuantEcon.qnwunif</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Computes quadrature nodes and weights for multivariate uniform distribution</p><p><strong>Arguments</strong></p><ul><li><code>n::Union{Int, Vector{Int}}</code> : Number of desired nodes along each dimension</li><li><code>a::Union{Real, Vector{Real}}</code> : Lower endpoint along each dimension</li><li><code>b::Union{Real, Vector{Real}}</code> : Upper endpoint along each dimension</li></ul><p><strong>Returns</strong></p><ul><li><code>nodes::Array{Float64}</code> : An array of quadrature nodes</li><li><code>weights::Array{Float64}</code> : An array of corresponding quadrature weights</li></ul><p><strong>Notes</strong></p><p>If any of the parameters to this function are scalars while others are <code>Vector</code>s of length <code>n</code>, the the scalar parameter is repeated <code>n</code> times.</p><p><strong>References</strong></p><p>Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and Finance, MIT Press, 2002.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.quadrect" href="#QuantEcon.quadrect"><code>QuantEcon.quadrect</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Integrate the d-dimensional function f on a rectangle with lower and upper bound for dimension i defined by a[i] and b[i], respectively; using n[i] points.</p><p><strong>Arguments</strong></p><ul><li><code>f::Function</code> The function to integrate over. This should be a function that accepts as its first argument a matrix representing points along each dimension (each dimension is a column). Other arguments that need to be passed to the function are caught by <code>args...</code> and `kwargs...``</li><li><code>n::Union{Int, Vector{Int}}</code> : Number of desired nodes along each dimension</li><li><code>a::Union{Real, Vector{Real}}</code> : Lower endpoint along each dimension</li><li><code>b::Union{Real, Vector{Real}}</code> : Upper endpoint along each dimension</li><li><code>kind::AbstractString(&quot;lege&quot;)</code> Specifies which type of integration to perform. Valid values are:     - <code>&quot;lege&quot;</code> : Gauss-Legendre     - <code>&quot;cheb&quot;</code> : Gauss-Chebyshev     - <code>&quot;trap&quot;</code> : trapezoid rule     - <code>&quot;simp&quot;</code> : Simpson rule     - <code>&quot;N&quot;</code> : Neiderreiter equidistributed sequence     - <code>&quot;W&quot;</code> : Weyl equidistributed sequence     - <code>&quot;H&quot;</code> : Haber  equidistributed sequence     - <code>&quot;R&quot;</code> : Monte Carlo     - <code>args...(Void)</code>: additional positional arguments to pass to <code>f</code>     - <code>;kwargs...(Void)</code>: additional keyword arguments to pass to <code>f</code></li></ul><p><strong>Returns</strong></p><ul><li><code>out::Float64</code> : The scalar that approximates integral of <code>f</code> on the hypercube formed by <code>[a, b]</code></li></ul><p><strong>References</strong></p><p>Miranda, Mario J, and Paul L Fackler. Applied Computational Economics and Finance, MIT Press, 2002.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.random_discrete_dp" href="#QuantEcon.random_discrete_dp"><code>QuantEcon.random_discrete_dp</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Generate a DiscreteDP randomly. The reward values are drawn from the normal distribution with mean 0 and standard deviation <code>scale</code>.</p><p><strong>Arguments</strong></p><ul><li><code>num_states::Integer</code> : Number of states.</li><li><code>num_actions::Integer</code> : Number of actions.</li><li><code>beta::Union{Float64, Void}(nothing)</code> : Discount factor. Randomly chosen from [0, 1) if not specified.</li><li><code>;k::Union{Integer, Void}(nothing)</code> : Number of possible next states for each state-action pair. Equal to <code>num_states</code> if not specified.</li></ul><ul><li><code>scale::Real(1)</code> : Standard deviation of the normal distribution for the reward values.</li></ul><p><strong>Returns</strong></p><ul><li><code>ddp::DiscreteDP</code> : An instance of DiscreteDP.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.random_markov_chain-Tuple{Integer,Integer}" href="#QuantEcon.random_markov_chain-Tuple{Integer,Integer}"><code>QuantEcon.random_markov_chain</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Return a randomly sampled MarkovChain instance with n states, where each state has k states with positive transition probability.</p><p><strong>Arguments</strong></p><ul><li><code>n::Integer</code> : Number of states.</li></ul><p><strong>Returns</strong></p><ul><li><code>mc::MarkovChain</code> : MarkovChain instance.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia">julia&gt; using QuantEcon

julia&gt; mc = random_markov_chain(3, 2)
Discrete Markov Chain
stochastic matrix:
3x3 Array{Float64,2}:
 0.369124  0.0       0.630876
 0.519035  0.480965  0.0
 0.0       0.744614  0.255386
</code></pre></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.random_markov_chain-Tuple{Integer}" href="#QuantEcon.random_markov_chain-Tuple{Integer}"><code>QuantEcon.random_markov_chain</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Return a randomly sampled MarkovChain instance with n states.</p><p><strong>Arguments</strong></p><ul><li><code>n::Integer</code> : Number of states.</li></ul><p><strong>Returns</strong></p><ul><li><code>mc::MarkovChain</code> : MarkovChain instance.</li></ul><p><strong>Examples</strong></p><pre><code class="language-julia">julia&gt; using QuantEcon

julia&gt; mc = random_markov_chain(3)
Discrete Markov Chain
stochastic matrix:
3x3 Array{Float64,2}:
 0.281188  0.61799   0.100822
 0.144461  0.848179  0.0073594
 0.360115  0.323973  0.315912
</code></pre></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.random_stochastic_matrix" href="#QuantEcon.random_stochastic_matrix"><code>QuantEcon.random_stochastic_matrix</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Return a randomly sampled n x n stochastic matrix with k nonzero entries for each row.</p><p><strong>Arguments</strong></p><ul><li><code>n::Integer</code> : Number of states.</li><li><code>k::Union{Integer, Void}(nothing)</code> : Number of nonzero entries in each column of the matrix. Set to n if note specified.</li></ul><p><strong>Returns</strong></p><ul><li><code>p::Array</code> : Stochastic matrix.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.recurrent_classes-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}}}" href="#QuantEcon.recurrent_classes-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}}}"><code>QuantEcon.recurrent_classes</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Find the recurrent classes of the Markov chain <code>mc</code>.</p><p><strong>Arguments</strong></p><ul><li><code>mc::MarkovChain</code> : MarkovChain instance.</li></ul><p><strong>Returns</strong></p><ul><li><code>::Vector{Vector{Int}}</code> : Vector of vectors that describe the recurrent classes of <code>mc</code>.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.replicate" href="#QuantEcon.replicate"><code>QuantEcon.replicate</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Simulate num_reps observations of x_T and y_T given x_0 ~ N(mu_0, Sigma_0).</p><p><strong>Arguments</strong></p><ul><li><code>lss::LSS</code> An instance of the Gaussian linear state space model.</li><li><code>t::Int = 10</code> The period that we want to replicate values for.</li><li><code>num_reps::Int = 100</code> The number of replications we want</li></ul><p><strong>Returns</strong></p><ul><li><code>x::Matrix</code> An n x num_reps matrix, where the j-th column is the j_th               observation of x_T</li><li><code>y::Matrix</code> An k x num_reps matrix, where the j-th column is the j_th               observation of y_T</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.robust_rule-Tuple{QuantEcon.RBLQ}" href="#QuantEcon.robust_rule-Tuple{QuantEcon.RBLQ}"><code>QuantEcon.robust_rule</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Solves the robust control problem.</p><p>The algorithm here tricks the problem into a stacked LQ problem, as described in chapter 2 of Hansen- Sargent&#39;s text &quot;Robustness.&quot;  The optimal control with observed state is</p><pre><code class="language-none">u_t = - F x_t</code></pre><p>And the value function is -x&#39;Px</p><p><strong>Arguments</strong></p><ul><li><code>rlq::RBLQ</code>: Instance of <code>RBLQ</code> type</li></ul><p><strong>Returns</strong></p><ul><li><code>F::Matrix{Float64}</code> : The optimal control matrix from above</li><li><code>P::Matrix{Float64}</code> : The positive semi-definite matrix defining the value function</li><li><code>K::Matrix{Float64}</code> : the worst-case shock matrix <code>K</code>, where <code>w_{t+1} = K x_t</code> is the worst case shock</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.robust_rule_simple" href="#QuantEcon.robust_rule_simple"><code>QuantEcon.robust_rule_simple</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Solve the robust LQ problem</p><p>A simple algorithm for computing the robust policy F and the corresponding value function P, based around straightforward iteration with the robust Bellman operator.  This function is easier to understand but one or two orders of magnitude slower than self.robust_rule().  For more information see the docstring of that method.</p><p><strong>Arguments</strong></p><ul><li><code>rlq::RBLQ</code>: Instance of <code>RBLQ</code> type</li><li><code>P_init::Matrix{Float64}(zeros(rlq.n, rlq.n))</code> : The initial guess for the value function matrix</li><li><code>;max_iter::Int(80)</code>: Maximum number of iterations that are allowed</li><li><code>;tol::Real(1e-8)</code> The tolerance for convergence</li></ul><p><strong>Returns</strong></p><ul><li><code>F::Matrix{Float64}</code> : The optimal control matrix from above</li><li><code>P::Matrix{Float64}</code> : The positive semi-definite matrix defining the value function</li><li><code>K::Matrix{Float64}</code> : the worst-case shock matrix <code>K</code>, where <code>w_{t+1} = K x_t</code> is the worst case shock</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.rouwenhorst" href="#QuantEcon.rouwenhorst"><code>QuantEcon.rouwenhorst</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Rouwenhorst&#39;s method to approximate AR(1) processes.</p><p>The process follows</p><pre><code class="language-none">y_t = μ + ρ y_{t-1} + ε_t,</code></pre><p>where ε_t ~ N (0, σ^2)</p><p><strong>Arguments</strong></p><ul><li><code>N::Integer</code> : Number of points in markov process</li><li><code>ρ::Real</code> : Persistence parameter in AR(1) process</li><li><code>σ::Real</code> : Standard deviation of random component of AR(1) process</li><li><code>μ::Real(0.0)</code> :  Mean of AR(1) process</li></ul><p><strong>Returns</strong></p><ul><li><code>mc::MarkovChain{Float64}</code> : Markov chain holding the state values and transition matrix</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.simulate!-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}},Array{Int64,2}}" href="#QuantEcon.simulate!-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}},Array{Int64,2}}"><code>QuantEcon.simulate!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Fill <code>X</code> with sample paths of the Markov chain <code>mc</code> as columns.</p><p><strong>Arguments</strong></p><ul><li><code>mc::MarkovChain</code> : MarkovChain instance.</li><li><code>X::Matrix{Int}</code> : Preallocated matrix of integers to be filled with sample paths of the markov chain <code>mc</code>. The elements in <code>X[1, :]</code> will be used as the initial states.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.simulate-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}},Int64,Array{Int64,1}}" href="#QuantEcon.simulate-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}},Int64,Array{Int64,1}}"><code>QuantEcon.simulate</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Simulate time series of state transitions of the Markov chain <code>mc</code>.</p><p>The sample path from the <code>j</code>-th repetition of the simulation with initial state <code>init[i]</code> is stored in the <code>(j-1)*num_reps+i</code>-th column of the matrix X.</p><p><strong>Arguments</strong></p><ul><li><code>mc::MarkovChain</code> : MarkovChain instance.</li><li><code>ts_length::Int</code> : Length of each simulation.</li><li><code>init::Vector{Int}</code> : Vector containing initial states.</li><li><code>;num_reps::Int(1)</code> : Number of repetitions of simulation for each element of <code>init</code>.</li></ul><p><strong>Returns</strong></p><ul><li><code>X::Matrix{Int}</code> : Array containing the sample paths as columns, of shape (ts_length, k), where k = length(init)* num_reps.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.simulate-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}},Int64,Int64}" href="#QuantEcon.simulate-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}},Int64,Int64}"><code>QuantEcon.simulate</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Simulate time series of state transitions of the Markov chain <code>mc</code>.</p><p><strong>Arguments</strong></p><ul><li><code>mc::MarkovChain</code> : MarkovChain instance.</li><li><code>ts_length::Int</code> : Length of each simulation.</li><li><code>init::Int</code> : Initial state.</li><li><code>;num_reps::Int(1)</code> : Number of repetitions of simulation.</li></ul><p><strong>Returns</strong></p><ul><li><code>X::Matrix{Int}</code> : Array containing the sample paths as columns, of shape (ts_length, k), where k = num_reps.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.simulate-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}},Int64}" href="#QuantEcon.simulate-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}},Int64}"><code>QuantEcon.simulate</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Simulate time series of state transitions of the Markov chain <code>mc</code>.</p><p><strong>Arguments</strong></p><ul><li><code>mc::MarkovChain</code> : MarkovChain instance.</li><li><code>ts_length::Int</code> : Length of each simulation.</li><li><code>;num_reps::Union{Int, Void}(nothing)</code> : Number of repetitions of simulation.</li></ul><p><strong>Returns</strong></p><ul><li><code>X::Matrix{Int}</code> : Array containing the sample paths as columns, of shape (ts_length, k), where k = num_reps.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.simulate_values" href="#QuantEcon.simulate_values"><code>QuantEcon.simulate_values</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Like <code>simulate(::MarkovChain, args...; kwargs...)</code>, but instead of returning integers specifying the state indices, this routine returns the values of the <code>mc.state_values</code> at each of those indices. See docstring for <code>simulate</code> for more information.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.simulate_values!" href="#QuantEcon.simulate_values!"><code>QuantEcon.simulate_values!</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Like <code>simulate(::MarkovChain, args...; kwargs...)</code>, but instead of returning integers specifying the state indices, this routine returns the values of the <code>mc.state_values</code> at each of those indices. See docstring for <code>simulate</code> for more information.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.simulation" href="#QuantEcon.simulation"><code>QuantEcon.simulation</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Simulate time series of state transitions of the Markov chain <code>mc</code>.</p><p><strong>Arguments</strong></p><ul><li><code>mc::MarkovChain</code> : MarkovChain instance.</li><li><code>ts_length::Int</code> : Length of each simulation.</li><li><code>init_state::Int(rand(1:n_states(mc)))</code> : Initial state.</li></ul><p><strong>Returns</strong></p><ul><li><code>x::Vector</code>: A vector of transition indices for a single simulation.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.simulation-Tuple{QuantEcon.ARMA}" href="#QuantEcon.simulation-Tuple{QuantEcon.ARMA}"><code>QuantEcon.simulation</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Compute a simulated sample path assuming Gaussian shocks.</p><p><strong>Arguments</strong></p><ul><li><code>arma::ARMA</code>: Instance of <code>ARMA</code> type</li><li><code>;ts_length::Integer(90)</code>: Length of simulation</li><li><code>;impulse_length::Integer(30)</code>: Horizon for calculating impulse response (see also docstring for <code>impulse_response</code>)</li></ul><p><strong>Returns</strong></p><ul><li><code>X::Vector{Float64}</code>: Simulation of the ARMA model <code>arma</code></li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.smooth" href="#QuantEcon.smooth"><code>QuantEcon.smooth</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Smooth the data in x using convolution with a window of requested size and type.</p><p><strong>Arguments</strong></p><ul><li><code>x::Array</code>: An array containing the data to smooth</li><li><code>window_len::Int(7)</code>: An odd integer giving the length of the window</li><li><code>window::AbstractString(&quot;hanning&quot;)</code>: A string giving the window type. Possible values are <code>flat</code>, <code>hanning</code>, <code>hamming</code>, <code>bartlett</code>, or <code>blackman</code></li></ul><p><strong>Returns</strong></p><ul><li><code>out::Array</code>: The array of smoothed data</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.smooth-Tuple{Array{T,N}}" href="#QuantEcon.smooth-Tuple{Array{T,N}}"><code>QuantEcon.smooth</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Version of <code>smooth</code> where <code>window_len</code> and <code>window</code> are keyword arguments</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.solve" href="#QuantEcon.solve"><code>QuantEcon.solve</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Solve the dynamic programming problem.</p><p><strong>Parameters</strong></p><ul><li><code>ddp::DiscreteDP</code> : Object that contains the Model Parameters</li><li><code>method::Type{T&lt;Algo}(VFI)</code>: Type name specifying solution method. Acceptable arguments are <code>VFI</code> for value function iteration or <code>PFI</code> for policy function iteration or <code>MPFI</code> for modified policy function iteration</li><li><code>;max_iter::Int(250)</code> : Maximum number of iterations</li><li><code>;epsilon::Float64(1e-3)</code> : Value for epsilon-optimality. Only used if <code>method</code> is <code>VFI</code></li><li><code>;k::Int(20)</code> : Number of iterations for partial policy evaluation in modified policy iteration (irrelevant for other methods).</li></ul><p><strong>Returns</strong></p><ul><li><code>ddpr::DPSolveResult{Algo}</code> : Optimization result represented as a DPSolveResult. See <code>DPSolveResult</code> for details.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.solve_discrete_lyapunov" href="#QuantEcon.solve_discrete_lyapunov"><code>QuantEcon.solve_discrete_lyapunov</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Solves the discrete lyapunov equation.</p><p>The problem is given by</p><pre><code class="language-none">AXA&#39; - X + B = 0</code></pre><p><code>X</code> is computed by using a doubling algorithm. In particular, we iterate to convergence on <code>X_j</code> with the following recursions for j = 1, 2,... starting from X_0 = B, a_0 = A:</p><pre><code class="language-none">a_j = a_{j-1} a_{j-1}
X_j = X_{j-1} + a_{j-1} X_{j-1} a_{j-1}&#39;</code></pre><p><strong>Arguments</strong></p><ul><li><code>A::Matrix{Float64}</code> : An n x n matrix as described above.  We assume in order for  convergence that the eigenvalues of <code>A</code> have moduli bounded by unity</li><li><code>B::Matrix{Float64}</code> :  An n x n matrix as described above.  We assume in order for convergence that the eigenvalues of <code>B</code> have moduli bounded by unity</li><li><code>max_it::Int(50)</code> :  Maximum number of iterations</li></ul><p><strong>Returns</strong></p><ul><li><code>gamma1::Matrix{Float64}</code> Represents the value X</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.solve_discrete_riccati" href="#QuantEcon.solve_discrete_riccati"><code>QuantEcon.solve_discrete_riccati</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Solves the discrete-time algebraic Riccati equation</p><p>The prolem is defined as</p><pre><code class="language-none">X = A&#39;XA - (N + B&#39;XA)&#39;(B&#39;XB + R)^{-1}(N + B&#39;XA) + Q</code></pre><p>via a modified structured doubling algorithm.  An explanation of the algorithm can be found in the reference below.</p><p><strong>Arguments</strong></p><ul><li><code>A</code> : k x k array.</li><li><code>B</code> : k x n array</li><li><code>R</code> : n x n, should be symmetric and positive definite</li><li><code>Q</code> : k x k, should be symmetric and non-negative definite</li><li><code>N::Matrix{Float64}(zeros(size(R, 1), size(Q, 1)))</code> : n x k array</li><li><code>tolerance::Float64(1e-10)</code> Tolerance level for convergence</li><li><code>max_iter::Int(50)</code> : The maximum number of iterations allowed</li></ul><p>Note that <code>A, B, R, Q</code> can either be real (i.e. k, n = 1) or matrices.</p><p><strong>Returns</strong></p><ul><li><code>X::Matrix{Float64}</code> The fixed point of the Riccati equation; a  k x k array representing the approximate solution</li></ul><p><strong>References</strong></p><p>Chiang, Chun-Yueh, Hung-Yuan Fan, and Wen-Wei Lin. &quot;STRUCTURED DOUBLING ALGORITHM FOR DISCRETE-TIME ALGEBRAIC RICCATI EQUATIONS WITH SINGULAR CONTROL WEIGHTING MATRICES.&quot; Taiwanese Journal of Mathematics 14, no. 3A (2010): pp-935.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.spectral_density-Tuple{QuantEcon.ARMA}" href="#QuantEcon.spectral_density-Tuple{QuantEcon.ARMA}"><code>QuantEcon.spectral_density</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Compute the spectral density function.</p><p>The spectral density is the discrete time Fourier transform of the autocovariance function. In particular,</p><pre><code class="language-none">f(w) = sum_k gamma(k) exp(-ikw)</code></pre><p>where gamma is the autocovariance function and the sum is over the set of all integers.</p><p><strong>Arguments</strong></p><ul><li><code>arma::ARMA</code>: Instance of <code>ARMA</code> type</li><li><code>;two_pi::Bool(true)</code>: Compute the spectral density function over [0, pi] if   false and [0, 2 pi] otherwise.</li><li><code>;res(1200)</code> : If <code>res</code> is a scalar then the spectral density is computed at <code>res</code> frequencies evenly spaced around the unit circle, but if <code>res</code> is an array then the function computes the response at the frequencies given by the array</li></ul><p><strong>Returns</strong></p><ul><li><code>w::Vector{Float64}</code>: The normalized frequencies at which h was computed, in   radians/sample</li><li><code>spect::Vector{Float64}</code> : The frequency response</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.stationary_distributions" href="#QuantEcon.stationary_distributions"><code>QuantEcon.stationary_distributions</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Compute stationary distributions of the Markov chain <code>mc</code>, one for each recurrent class.</p><p><strong>Arguments</strong></p><ul><li><code>mc::MarkovChain{T}</code> : MarkovChain instance.</li></ul><p><strong>Returns</strong></p><ul><li><code>stationary_dists::Vector{Vector{T1}}</code> : Vector of vectors that represent   stationary distributions, where the element type <code>T1</code> is <code>Rational</code> if <code>T</code> is   <code>Int</code> (and equal to <code>T</code> otherwise).</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.stationary_distributions-Tuple{QuantEcon.LSS}" href="#QuantEcon.stationary_distributions-Tuple{QuantEcon.LSS}"><code>QuantEcon.stationary_distributions</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Compute the moments of the stationary distributions of x_t and y_t if possible.  Computation is by iteration, starting from the initial conditions lss.mu_0 and lss.Sigma_0</p><p><strong>Arguments</strong></p><ul><li><code>lss::LSS</code> An instance of the Guassian linear state space model</li><li><code>;max_iter::Int = 200</code> The maximum number of iterations allowed</li><li><code>;tol::Float64 = 1e-5</code> The tolerance level one wishes to achieve</li></ul><p><strong>Returns</strong></p><ul><li><code>mu_x::Vector</code> Represents the stationary mean of x_t</li><li><code>mu_y::Vector</code>Represents the stationary mean of y_t</li><li><code>Sigma_x::Matrix</code> Represents the var-cov matrix</li><li><code>Sigma_y::Matrix</code> Represents the var-cov matrix</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.stationary_values!-Tuple{QuantEcon.LQ}" href="#QuantEcon.stationary_values!-Tuple{QuantEcon.LQ}"><code>QuantEcon.stationary_values!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Computes value and policy functions in infinite horizon model</p><p><strong>Arguments</strong></p><ul><li><code>lq::LQ</code> : instance of <code>LQ</code> type</li></ul><p><strong>Returns</strong></p><ul><li><code>P::ScalarOrArray</code> : n x n matrix in value function representation V(x) = x&#39;Px + d</li><li><code>d::Real</code> : Constant in value function representation</li><li><code>F::ScalarOrArray</code> : Policy rule that specifies optimal control in each period</li></ul><p><strong>Notes</strong></p><p>This function updates the <code>P</code>, <code>d</code>, and <code>F</code> fields on the <code>lq</code> instance in addition to returning them</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.stationary_values-Tuple{QuantEcon.LQ}" href="#QuantEcon.stationary_values-Tuple{QuantEcon.LQ}"><code>QuantEcon.stationary_values</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Non-mutating routine for solving for <code>P</code>, <code>d</code>, and <code>F</code> in infinite horizon model</p><p>See docstring for stationary_values! for more explanation</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.tauchen" href="#QuantEcon.tauchen"><code>QuantEcon.tauchen</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Tauchen&#39;s (1996) method for approximating AR(1) process with finite markov chain</p><p>The process follows</p><pre><code class="language-none">y_t = μ + ρ y_{t-1} + ε_t,</code></pre><p>where ε_t ~ N (0, σ^2)</p><p><strong>Arguments</strong></p><ul><li><code>N::Integer</code>: Number of points in markov process</li><li><code>ρ::Real</code> : Persistence parameter in AR(1) process</li><li><code>σ::Real</code> : Standard deviation of random component of AR(1) process</li><li><code>μ::Real(0.0)</code> : Mean of AR(1) process</li><li><code>n_std::Integer(3)</code> : The number of standard deviations to each side the process should span</li></ul><p><strong>Returns</strong></p><ul><li><code>mc::MarkovChain{Float64}</code> : Markov chain holding the state values and transition matrix</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.update!-Tuple{QuantEcon.Kalman,Any}" href="#QuantEcon.update!-Tuple{QuantEcon.Kalman,Any}"><code>QuantEcon.update!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Updates cur_x_hat and cur_sigma given array <code>y</code> of length <code>k</code>.  The full update, from one period to the next</p><p><strong>Arguments</strong></p><ul><li><code>k::Kalman</code> An instance of the Kalman filter</li><li><code>y</code> An array representing the current measurement</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.update_values!-Tuple{QuantEcon.LQ}" href="#QuantEcon.update_values!-Tuple{QuantEcon.LQ}"><code>QuantEcon.update_values!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Update <code>P</code> and <code>d</code> from the value function representation in finite horizon case</p><p><strong>Arguments</strong></p><ul><li><code>lq::LQ</code> : instance of <code>LQ</code> type</li></ul><p><strong>Returns</strong></p><ul><li><code>P::ScalarOrArray</code> : n x n matrix in value function representation V(x) = x&#39;Px + d</li><li><code>d::Real</code> : Constant in value function representation</li></ul><p><strong>Notes</strong></p><p>This function updates the <code>P</code> and <code>d</code> fields on the <code>lq</code> instance in addition to returning them</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.value_simulation" href="#QuantEcon.value_simulation"><code>QuantEcon.value_simulation</code></a> — <span class="docstring-category">Function</span>.</div><div><p>Simulate time series of state transitions of the Markov chain <code>mc</code>.</p><p><strong>Arguments</strong></p><ul><li><code>mc::MarkovChain</code> : MarkovChain instance.</li><li><code>ts_length::Int</code> : Length of each simulation.</li><li><code>init_state::Int(rand(1:n_states(mc)))</code> : Initial state.</li></ul><p><strong>Returns</strong></p><ul><li><code>x::Vector</code>: A vector of state values along a simulated path.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.var_quadratic_sum-Tuple{Union{Array{T,N},T},Union{Array{T,N},T},Union{Array{T,N},T},Real,Union{Array{T,N},T}}" href="#QuantEcon.var_quadratic_sum-Tuple{Union{Array{T,N},T},Union{Array{T,N},T},Union{Array{T,N},T},Real,Union{Array{T,N},T}}"><code>QuantEcon.var_quadratic_sum</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Computes the expected discounted quadratic sum</p><pre><code class="language-none">q(x_0) = E sum_{t=0}^{infty} beta^t x_t&#39; H x_t</code></pre><p>Here {x_t} is the VAR process x_{t+1} = A x_t + C w_t with {w_t} standard normal and x_0 the initial condition.</p><p><strong>Arguments</strong></p><ul><li><code>A::Union{Float64, Matrix{Float64}}</code> The n x n matrix described above (scalar) if n = 1</li><li><code>C::Union{Float64, Matrix{Float64}}</code> The n x n matrix described above (scalar) if n = 1</li><li><code>H::Union{Float64, Matrix{Float64}}</code> The n x n matrix described above (scalar) if n = 1</li><li><code>beta::Float64</code>: Discount factor in (0, 1)</li><li><code>x_0::Union{Float64, Vector{Float64}}</code> The initial condtion. A conformable array (of length n) or a scalar if n=1</li></ul><p><strong>Returns</strong></p><ul><li><code>q0::Float64</code> : Represents the value q(x_0)</li></ul><p><strong>Notes</strong></p><p>The formula for computing q(x_0) is q(x_0) = x_0&#39; Q x_0 + v where</p><ul><li>Q is the solution to Q = H + beta A&#39; Q A and</li><li>v = 	race(C&#39; Q C) eta / (1 - eta)</li></ul></div></section><h2><a class="nav-anchor" id="Internal-1" href="#Internal-1">Internal</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.DPSolveResult" href="#QuantEcon.DPSolveResult"><code>QuantEcon.DPSolveResult</code></a> — <span class="docstring-category">Type</span>.</div><div><p>DPSolveResult is an object for retaining results and associated metadata after solving the model</p><p><strong>Parameters</strong></p><ul><li><code>ddp::DiscreteDP</code> : DiscreteDP object</li></ul><p><strong>Returns</strong></p><ul><li><code>ddpr::DPSolveResult</code> : DiscreteDP Results object</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.*-Tuple{Array{T,3},Array{T,1}}" href="#Base.*-Tuple{Array{T,3},Array{T,1}}"><code>Base.*</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Define Matrix Multiplication between 3-dimensional matrix and a vector</p><p>Matrix multiplication over the last dimension of A</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon._compute_sequence-Tuple{QuantEcon.LQ,Array{T,1},Any}" href="#QuantEcon._compute_sequence-Tuple{QuantEcon.LQ,Array{T,1},Any}"><code>QuantEcon._compute_sequence</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Private method implementing <code>compute_sequence</code> when state is a scalar</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon._compute_sequence-Tuple{QuantEcon.LQ,T,Any}" href="#QuantEcon._compute_sequence-Tuple{QuantEcon.LQ,T,Any}"><code>QuantEcon._compute_sequence</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Private method implementing <code>compute_sequence</code> when state is a scalar</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon._generate_a_indptr!-Tuple{Int64,Array{T,1},Array{T,1}}" href="#QuantEcon._generate_a_indptr!-Tuple{Int64,Array{T,1},Array{T,1}}"><code>QuantEcon._generate_a_indptr!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Generate <code>a_indptr</code>; stored in <code>out</code>. <code>s_indices</code> is assumed to be in sorted order.</p><p><strong>Parameters</strong></p><p>num_states : Int</p><p>s_indices : Vector{Int}</p><p>out : Vector{Int} with length = num_states+1</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon._has_sorted_sa_indices-Tuple{Array{T,1},Array{T,1}}" href="#QuantEcon._has_sorted_sa_indices-Tuple{Array{T,1},Array{T,1}}"><code>QuantEcon._has_sorted_sa_indices</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Check whether <code>s_indices</code> and <code>a_indices</code> are sorted in lexicographic order.</p><p><strong>Parameters</strong></p><p>s_indices, a_indices : Vectors</p><p><strong>Returns</strong></p><p>bool: Whether <code>s_indices</code> and <code>a_indices</code> are sorted.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon._random_stochastic_matrix-Tuple{Integer,Integer}" href="#QuantEcon._random_stochastic_matrix-Tuple{Integer,Integer}"><code>QuantEcon._random_stochastic_matrix</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Generate a &quot;non-square column stochstic matrix&quot; of shape (n, m), which contains as columns m probability vectors of length n with k nonzero entries.</p><p><strong>Arguments</strong></p><ul><li><code>n::Integer</code> : Number of states.</li><li><code>m::Integer</code> : Number of probability vectors.</li><li><code>;k::Union{Integer, Void}(nothing)</code> : Number of nonzero entries in each column of the matrix. Set to n if note specified.</li></ul><p><strong>Returns</strong></p><ul><li><code>p::Array</code> : Array of shape (n, m) containing m probability vectors of length n as columns.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon._solve!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{QuantEcon.MPFI,Tval<:Real},Integer,Real,Integer}" href="#QuantEcon._solve!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{QuantEcon.MPFI,Tval<:Real},Integer,Real,Integer}"><code>QuantEcon._solve!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Modified Policy Function Iteration</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon._solve!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{QuantEcon.PFI,Tval<:Real},Integer,Real,Integer}" href="#QuantEcon._solve!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{QuantEcon.PFI,Tval<:Real},Integer,Real,Integer}"><code>QuantEcon._solve!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Policy Function Iteration</p><p>NOTE: The epsilon is ignored in this method. It is only here so dispatch can       go from <code>solve(::DiscreteDP, ::Type{Algo})</code> to any of the algorithms.       See <code>solve</code> for further details</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon._solve!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{QuantEcon.VFI,Tval<:Real},Integer,Real,Integer}" href="#QuantEcon._solve!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{QuantEcon.VFI,Tval<:Real},Integer,Real,Integer}"><code>QuantEcon._solve!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Impliments Value Iteration NOTE: See <code>solve</code> for further details</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.fix" href="#QuantEcon.fix"><code>QuantEcon.fix</code></a> — <span class="docstring-category">Function</span>.</div><div><p><code>fix(x)</code></p><p>Round <code>x</code> towards zero. For arrays there is a mutating version <code>fix!</code></p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.gth_solve!-Tuple{Array{T<:Real,2}}" href="#QuantEcon.gth_solve!-Tuple{Array{T<:Real,2}}"><code>QuantEcon.gth_solve!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Same as <code>gth_solve</code>, but overwrite the input <code>A</code>, instead of creating a copy.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.random_probvec-Tuple{Integer,Integer}" href="#QuantEcon.random_probvec-Tuple{Integer,Integer}"><code>QuantEcon.random_probvec</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Return m randomly sampled probability vectors of size k.</p><p><strong>Arguments</strong></p><ul><li><code>k::Integer</code> : Size of each probability vector.</li><li><code>m::Integer</code> : Number of probability vectors.</li></ul><p><strong>Returns</strong></p><ul><li><code>a::Array</code> : Array of shape (k, m) containing probability vectors as colums.</li></ul></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.s_wise_max!-Tuple{AbstractArray{T,2},Array{T,1},Array{T,1}}" href="#QuantEcon.s_wise_max!-Tuple{AbstractArray{T,2},Array{T,1},Array{T,1}}"><code>QuantEcon.s_wise_max!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Populate <code>out</code> with  <code>max_a vals(s, a)</code>,  where <code>vals</code> is represented as a <code>AbstractMatrix</code> of size <code>(num_states, num_actions)</code>.</p><p>Also fills <code>out_argmax</code> with the column number associated with the indmax in each row</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.s_wise_max!-Tuple{AbstractArray{T,2},Array{T,1}}" href="#QuantEcon.s_wise_max!-Tuple{AbstractArray{T,2},Array{T,1}}"><code>QuantEcon.s_wise_max!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Populate <code>out</code> with  <code>max_a vals(s, a)</code>,  where <code>vals</code> is represented as a <code>AbstractMatrix</code> of size <code>(num_states, num_actions)</code>.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.s_wise_max!-Tuple{Array{T,1},Array{T,1},Array{T,1},Array{T,1},Array{T,1}}" href="#QuantEcon.s_wise_max!-Tuple{Array{T,1},Array{T,1},Array{T,1},Array{T,1},Array{T,1}}"><code>QuantEcon.s_wise_max!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Populate <code>out</code> with  <code>max_a vals(s, a)</code>,  where <code>vals</code> is represented as a <code>Vector</code> of size <code>(num_sa_pairs,)</code>.</p><p>Also fills <code>out_argmax</code> with the cartesiean index associated with the indmax in each row</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.s_wise_max!-Tuple{Array{T,1},Array{T,1},Array{T,1},Array{T,1}}" href="#QuantEcon.s_wise_max!-Tuple{Array{T,1},Array{T,1},Array{T,1},Array{T,1}}"><code>QuantEcon.s_wise_max!</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Populate <code>out</code> with  <code>max_a vals(s, a)</code>,  where <code>vals</code> is represented as a <code>Vector</code> of size <code>(num_sa_pairs,)</code>.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.s_wise_max-Tuple{AbstractArray{T,2}}" href="#QuantEcon.s_wise_max-Tuple{AbstractArray{T,2}}"><code>QuantEcon.s_wise_max</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Return the <code>Vector</code> <code>max_a vals(s, a)</code>,  where <code>vals</code> is represented as a <code>AbstractMatrix</code> of size <code>(num_states, num_actions)</code>.</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.todense-Tuple{Type{T},Array{T,N}}" href="#QuantEcon.todense-Tuple{Type{T},Array{T,N}}"><code>QuantEcon.todense</code></a> — <span class="docstring-category">Method</span>.</div><div><p>If A is already dense, return A as is</p></div></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="QuantEcon.todense-Tuple{Type{T},SparseMatrixCSC{Tv,Ti<:Integer}}" href="#QuantEcon.todense-Tuple{Type{T},SparseMatrixCSC{Tv,Ti<:Integer}}"><code>QuantEcon.todense</code></a> — <span class="docstring-category">Method</span>.</div><div><p>Custom version of <code>full</code>, which allows convertion to type T</p></div></section><h2><a class="nav-anchor" id="Index-1" href="#Index-1">Index</a></h2><ul><li><a href="QuantEcon.html#QuantEcon.ARMA"><code>QuantEcon.ARMA</code></a></li><li><a href="QuantEcon.html#QuantEcon.DPSolveResult"><code>QuantEcon.DPSolveResult</code></a></li><li><a href="QuantEcon.html#QuantEcon.DiscreteDP-Tuple{AbstractArray{T,NR},AbstractArray{T,NQ},Tbeta,Array{Tind,1},Array{Tind,1}}"><code>QuantEcon.DiscreteDP</code></a></li><li><a href="QuantEcon.html#QuantEcon.DiscreteDP-Tuple{Array{T,NR},Array{T,NQ},Tbeta}"><code>QuantEcon.DiscreteDP</code></a></li><li><a href="QuantEcon.html#QuantEcon.DiscreteDP"><code>QuantEcon.DiscreteDP</code></a></li><li><a href="QuantEcon.html#QuantEcon.DiscreteRV"><code>QuantEcon.DiscreteRV</code></a></li><li><a href="QuantEcon.html#QuantEcon.ECDF"><code>QuantEcon.ECDF</code></a></li><li><a href="QuantEcon.html#QuantEcon.LAE"><code>QuantEcon.LAE</code></a></li><li><a href="QuantEcon.html#QuantEcon.LQ"><code>QuantEcon.LQ</code></a></li><li><a href="QuantEcon.html#QuantEcon.LQ"><code>QuantEcon.LQ</code></a></li><li><a href="QuantEcon.html#QuantEcon.LQ"><code>QuantEcon.LQ</code></a></li><li><a href="QuantEcon.html#QuantEcon.LSS"><code>QuantEcon.LSS</code></a></li><li><a href="QuantEcon.html#QuantEcon.MPFI"><code>QuantEcon.MPFI</code></a></li><li><a href="QuantEcon.html#QuantEcon.MarkovChain"><code>QuantEcon.MarkovChain</code></a></li><li><a href="QuantEcon.html#QuantEcon.MarkovChain-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{Algo<:QuantEcon.DDPAlgorithm,Tval<:Real}}"><code>QuantEcon.MarkovChain</code></a></li><li><a href="QuantEcon.html#QuantEcon.PFI"><code>QuantEcon.PFI</code></a></li><li><a href="QuantEcon.html#QuantEcon.RBLQ"><code>QuantEcon.RBLQ</code></a></li><li><a href="QuantEcon.html#QuantEcon.VFI"><code>QuantEcon.VFI</code></a></li><li><a href="QuantEcon.html#Base.*-Tuple{Array{T,3},Array{T,1}}"><code>Base.*</code></a></li><li><a href="QuantEcon.html#LightGraphs.period-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}}}"><code>LightGraphs.period</code></a></li><li><a href="QuantEcon.html#QuantEcon.F_to_K-Tuple{QuantEcon.RBLQ,Array{T,2}}"><code>QuantEcon.F_to_K</code></a></li><li><a href="QuantEcon.html#QuantEcon.K_to_F-Tuple{QuantEcon.RBLQ,Array{T,2}}"><code>QuantEcon.K_to_F</code></a></li><li><a href="QuantEcon.html#QuantEcon.RQ_sigma-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{Algo<:QuantEcon.DDPAlgorithm,Tval<:Real}}"><code>QuantEcon.RQ_sigma</code></a></li><li><a href="QuantEcon.html#QuantEcon.RQ_sigma-Tuple{QuantEcon.DiscreteDP{T,3,2,Tbeta,Tind},Array{T<:Integer,N}}"><code>QuantEcon.RQ_sigma</code></a></li><li><a href="QuantEcon.html#QuantEcon._compute_sequence-Tuple{QuantEcon.LQ,Array{T,1},Any}"><code>QuantEcon._compute_sequence</code></a></li><li><a href="QuantEcon.html#QuantEcon._compute_sequence-Tuple{QuantEcon.LQ,T,Any}"><code>QuantEcon._compute_sequence</code></a></li><li><a href="QuantEcon.html#QuantEcon._generate_a_indptr!-Tuple{Int64,Array{T,1},Array{T,1}}"><code>QuantEcon._generate_a_indptr!</code></a></li><li><a href="QuantEcon.html#QuantEcon._has_sorted_sa_indices-Tuple{Array{T,1},Array{T,1}}"><code>QuantEcon._has_sorted_sa_indices</code></a></li><li><a href="QuantEcon.html#QuantEcon._random_stochastic_matrix-Tuple{Integer,Integer}"><code>QuantEcon._random_stochastic_matrix</code></a></li><li><a href="QuantEcon.html#QuantEcon._solve!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{QuantEcon.MPFI,Tval<:Real},Integer,Real,Integer}"><code>QuantEcon._solve!</code></a></li><li><a href="QuantEcon.html#QuantEcon._solve!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{QuantEcon.PFI,Tval<:Real},Integer,Real,Integer}"><code>QuantEcon._solve!</code></a></li><li><a href="QuantEcon.html#QuantEcon._solve!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{QuantEcon.VFI,Tval<:Real},Integer,Real,Integer}"><code>QuantEcon._solve!</code></a></li><li><a href="QuantEcon.html#QuantEcon.ar_periodogram"><code>QuantEcon.ar_periodogram</code></a></li><li><a href="QuantEcon.html#QuantEcon.autocovariance-Tuple{QuantEcon.ARMA}"><code>QuantEcon.autocovariance</code></a></li><li><a href="QuantEcon.html#QuantEcon.b_operator-Tuple{QuantEcon.RBLQ,Array{T,2}}"><code>QuantEcon.b_operator</code></a></li><li><a href="QuantEcon.html#QuantEcon.bellman_operator-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},Array{T,1}}"><code>QuantEcon.bellman_operator</code></a></li><li><a href="QuantEcon.html#QuantEcon.bellman_operator!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},Array{T<:AbstractFloat,1},Array{T,1}}"><code>QuantEcon.bellman_operator!</code></a></li><li><a href="QuantEcon.html#QuantEcon.bellman_operator!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{Algo<:QuantEcon.DDPAlgorithm,Tval<:Real}}"><code>QuantEcon.bellman_operator!</code></a></li><li><a href="QuantEcon.html#QuantEcon.bellman_operator!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},Array{T,1},Array{T,1},Array{T,1}}"><code>QuantEcon.bellman_operator!</code></a></li><li><a href="QuantEcon.html#QuantEcon.ckron"><code>QuantEcon.ckron</code></a></li><li><a href="QuantEcon.html#QuantEcon.communication_classes-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}}}"><code>QuantEcon.communication_classes</code></a></li><li><a href="QuantEcon.html#QuantEcon.compute_deterministic_entropy-Tuple{QuantEcon.RBLQ,Any,Any,Any}"><code>QuantEcon.compute_deterministic_entropy</code></a></li><li><a href="QuantEcon.html#QuantEcon.compute_fixed_point-Tuple{Function,TV}"><code>QuantEcon.compute_fixed_point</code></a></li><li><a href="QuantEcon.html#QuantEcon.compute_greedy-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},Array{TV<:Real,1}}"><code>QuantEcon.compute_greedy</code></a></li><li><a href="QuantEcon.html#QuantEcon.compute_greedy!-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{Algo<:QuantEcon.DDPAlgorithm,Tval<:Real}}"><code>QuantEcon.compute_greedy!</code></a></li><li><a href="QuantEcon.html#QuantEcon.compute_sequence"><code>QuantEcon.compute_sequence</code></a></li><li><a href="QuantEcon.html#QuantEcon.d_operator-Tuple{QuantEcon.RBLQ,Array{T,2}}"><code>QuantEcon.d_operator</code></a></li><li><a href="QuantEcon.html#QuantEcon.do_quad-Tuple{Function,Array{T,N},Array{T,1},Vararg{Any}}"><code>QuantEcon.do_quad</code></a></li><li><a href="QuantEcon.html#QuantEcon.draw-Tuple{QuantEcon.DiscreteRV{TV1<:AbstractArray{T,1},TV2<:AbstractArray{T,1}}}"><code>QuantEcon.draw</code></a></li><li><a href="QuantEcon.html#QuantEcon.draw-Tuple{QuantEcon.DiscreteRV{TV1<:AbstractArray{T,1},TV2<:AbstractArray{T,1}},Int64}"><code>QuantEcon.draw</code></a></li><li><a href="QuantEcon.html#QuantEcon.ecdf"><code>QuantEcon.ecdf</code></a></li><li><a href="QuantEcon.html#QuantEcon.evaluate_F-Tuple{QuantEcon.RBLQ,Array{T,2}}"><code>QuantEcon.evaluate_F</code></a></li><li><a href="QuantEcon.html#QuantEcon.evaluate_policy-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},Array{T<:Integer,1}}"><code>QuantEcon.evaluate_policy</code></a></li><li><a href="QuantEcon.html#QuantEcon.evaluate_policy-Tuple{QuantEcon.DiscreteDP{T<:Real,NQ,NR,Tbeta<:Real,Tind},QuantEcon.DPSolveResult{Algo<:QuantEcon.DDPAlgorithm,Tval<:Real}}"><code>QuantEcon.evaluate_policy</code></a></li><li><a href="QuantEcon.html#QuantEcon.filtered_to_forecast!-Tuple{QuantEcon.Kalman}"><code>QuantEcon.filtered_to_forecast!</code></a></li><li><a href="QuantEcon.html#QuantEcon.fix"><code>QuantEcon.fix</code></a></li><li><a href="QuantEcon.html#QuantEcon.gridmake"><code>QuantEcon.gridmake</code></a></li><li><a href="QuantEcon.html#QuantEcon.gridmake!-Tuple{Any,Vararg{AbstractArray{T,1}}}"><code>QuantEcon.gridmake!</code></a></li><li><a href="QuantEcon.html#QuantEcon.gth_solve-Tuple{Array{T<:Real,2}}"><code>QuantEcon.gth_solve</code></a></li><li><a href="QuantEcon.html#QuantEcon.gth_solve!-Tuple{Array{T<:Real,2}}"><code>QuantEcon.gth_solve!</code></a></li><li><a href="QuantEcon.html#QuantEcon.impulse_response-Tuple{QuantEcon.ARMA}"><code>QuantEcon.impulse_response</code></a></li><li><a href="QuantEcon.html#QuantEcon.is_aperiodic-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}}}"><code>QuantEcon.is_aperiodic</code></a></li><li><a href="QuantEcon.html#QuantEcon.is_irreducible-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}}}"><code>QuantEcon.is_irreducible</code></a></li><li><a href="QuantEcon.html#QuantEcon.lae_est-Tuple{QuantEcon.LAE,AbstractArray{T,N}}"><code>QuantEcon.lae_est</code></a></li><li><a href="QuantEcon.html#QuantEcon.m_quadratic_sum-Tuple{Array{T,2},Array{T,2}}"><code>QuantEcon.m_quadratic_sum</code></a></li><li><a href="QuantEcon.html#QuantEcon.moment_sequence-Tuple{QuantEcon.LSS}"><code>QuantEcon.moment_sequence</code></a></li><li><a href="QuantEcon.html#QuantEcon.n_states-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}}}"><code>QuantEcon.n_states</code></a></li><li><a href="QuantEcon.html#QuantEcon.nnash-Tuple{Any,Any,Any,Any,Any,Any,Any,Any,Any,Any,Any,Any,Any}"><code>QuantEcon.nnash</code></a></li><li><a href="QuantEcon.html#QuantEcon.periodogram"><code>QuantEcon.periodogram</code></a></li><li><a href="QuantEcon.html#QuantEcon.prior_to_filtered!-Tuple{QuantEcon.Kalman,Any}"><code>QuantEcon.prior_to_filtered!</code></a></li><li><a href="QuantEcon.html#QuantEcon.qnwbeta-Tuple{Int64,Real,Real}"><code>QuantEcon.qnwbeta</code></a></li><li><a href="QuantEcon.html#QuantEcon.qnwcheb-Tuple{Int64,Real,Real}"><code>QuantEcon.qnwcheb</code></a></li><li><a href="QuantEcon.html#QuantEcon.qnwequi"><code>QuantEcon.qnwequi</code></a></li><li><a href="QuantEcon.html#QuantEcon.qnwgamma"><code>QuantEcon.qnwgamma</code></a></li><li><a href="QuantEcon.html#QuantEcon.qnwlege-Tuple{Int64,Real,Real}"><code>QuantEcon.qnwlege</code></a></li><li><a href="QuantEcon.html#QuantEcon.qnwlogn-Tuple{Any,Any,Any}"><code>QuantEcon.qnwlogn</code></a></li><li><a href="QuantEcon.html#QuantEcon.qnwnorm-Tuple{Int64}"><code>QuantEcon.qnwnorm</code></a></li><li><a href="QuantEcon.html#QuantEcon.qnwsimp-Tuple{Int64,Real,Real}"><code>QuantEcon.qnwsimp</code></a></li><li><a href="QuantEcon.html#QuantEcon.qnwtrap-Tuple{Int64,Real,Real}"><code>QuantEcon.qnwtrap</code></a></li><li><a href="QuantEcon.html#QuantEcon.qnwunif-Tuple{Any,Any,Any}"><code>QuantEcon.qnwunif</code></a></li><li><a href="QuantEcon.html#QuantEcon.quadrect"><code>QuantEcon.quadrect</code></a></li><li><a href="QuantEcon.html#QuantEcon.random_discrete_dp"><code>QuantEcon.random_discrete_dp</code></a></li><li><a href="QuantEcon.html#QuantEcon.random_markov_chain-Tuple{Integer,Integer}"><code>QuantEcon.random_markov_chain</code></a></li><li><a href="QuantEcon.html#QuantEcon.random_markov_chain-Tuple{Integer}"><code>QuantEcon.random_markov_chain</code></a></li><li><a href="QuantEcon.html#QuantEcon.random_probvec-Tuple{Integer,Integer}"><code>QuantEcon.random_probvec</code></a></li><li><a href="QuantEcon.html#QuantEcon.random_stochastic_matrix"><code>QuantEcon.random_stochastic_matrix</code></a></li><li><a href="QuantEcon.html#QuantEcon.recurrent_classes-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}}}"><code>QuantEcon.recurrent_classes</code></a></li><li><a href="QuantEcon.html#QuantEcon.replicate"><code>QuantEcon.replicate</code></a></li><li><a href="QuantEcon.html#QuantEcon.robust_rule-Tuple{QuantEcon.RBLQ}"><code>QuantEcon.robust_rule</code></a></li><li><a href="QuantEcon.html#QuantEcon.robust_rule_simple"><code>QuantEcon.robust_rule_simple</code></a></li><li><a href="QuantEcon.html#QuantEcon.rouwenhorst"><code>QuantEcon.rouwenhorst</code></a></li><li><a href="QuantEcon.html#QuantEcon.s_wise_max-Tuple{AbstractArray{T,2}}"><code>QuantEcon.s_wise_max</code></a></li><li><a href="QuantEcon.html#QuantEcon.s_wise_max!-Tuple{Array{T,1},Array{T,1},Array{T,1},Array{T,1},Array{T,1}}"><code>QuantEcon.s_wise_max!</code></a></li><li><a href="QuantEcon.html#QuantEcon.s_wise_max!-Tuple{Array{T,1},Array{T,1},Array{T,1},Array{T,1}}"><code>QuantEcon.s_wise_max!</code></a></li><li><a href="QuantEcon.html#QuantEcon.s_wise_max!-Tuple{AbstractArray{T,2},Array{T,1}}"><code>QuantEcon.s_wise_max!</code></a></li><li><a href="QuantEcon.html#QuantEcon.s_wise_max!-Tuple{AbstractArray{T,2},Array{T,1},Array{T,1}}"><code>QuantEcon.s_wise_max!</code></a></li><li><a href="QuantEcon.html#QuantEcon.simulate-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}},Int64,Int64}"><code>QuantEcon.simulate</code></a></li><li><a href="QuantEcon.html#QuantEcon.simulate-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}},Int64,Array{Int64,1}}"><code>QuantEcon.simulate</code></a></li><li><a href="QuantEcon.html#QuantEcon.simulate-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}},Int64}"><code>QuantEcon.simulate</code></a></li><li><a href="QuantEcon.html#QuantEcon.simulate!-Tuple{QuantEcon.MarkovChain{T,TM<:AbstractArray{T,2},TV<:AbstractArray{T,1}},Array{Int64,2}}"><code>QuantEcon.simulate!</code></a></li><li><a href="QuantEcon.html#QuantEcon.simulate_values"><code>QuantEcon.simulate_values</code></a></li><li><a href="QuantEcon.html#QuantEcon.simulate_values!"><code>QuantEcon.simulate_values!</code></a></li><li><a href="QuantEcon.html#QuantEcon.simulation"><code>QuantEcon.simulation</code></a></li><li><a href="QuantEcon.html#QuantEcon.simulation-Tuple{QuantEcon.ARMA}"><code>QuantEcon.simulation</code></a></li><li><a href="QuantEcon.html#QuantEcon.smooth-Tuple{Array{T,N}}"><code>QuantEcon.smooth</code></a></li><li><a href="QuantEcon.html#QuantEcon.smooth"><code>QuantEcon.smooth</code></a></li><li><a href="QuantEcon.html#QuantEcon.solve"><code>QuantEcon.solve</code></a></li><li><a href="QuantEcon.html#QuantEcon.solve_discrete_lyapunov"><code>QuantEcon.solve_discrete_lyapunov</code></a></li><li><a href="QuantEcon.html#QuantEcon.solve_discrete_riccati"><code>QuantEcon.solve_discrete_riccati</code></a></li><li><a href="QuantEcon.html#QuantEcon.spectral_density-Tuple{QuantEcon.ARMA}"><code>QuantEcon.spectral_density</code></a></li><li><a href="QuantEcon.html#QuantEcon.stationary_distributions"><code>QuantEcon.stationary_distributions</code></a></li><li><a href="QuantEcon.html#QuantEcon.stationary_distributions-Tuple{QuantEcon.LSS}"><code>QuantEcon.stationary_distributions</code></a></li><li><a href="QuantEcon.html#QuantEcon.stationary_values-Tuple{QuantEcon.LQ}"><code>QuantEcon.stationary_values</code></a></li><li><a href="QuantEcon.html#QuantEcon.stationary_values!-Tuple{QuantEcon.LQ}"><code>QuantEcon.stationary_values!</code></a></li><li><a href="QuantEcon.html#QuantEcon.tauchen"><code>QuantEcon.tauchen</code></a></li><li><a href="QuantEcon.html#QuantEcon.todense-Tuple{Type{T},SparseMatrixCSC{Tv,Ti<:Integer}}"><code>QuantEcon.todense</code></a></li><li><a href="QuantEcon.html#QuantEcon.todense-Tuple{Type{T},Array{T,N}}"><code>QuantEcon.todense</code></a></li><li><a href="QuantEcon.html#QuantEcon.update!-Tuple{QuantEcon.Kalman,Any}"><code>QuantEcon.update!</code></a></li><li><a href="QuantEcon.html#QuantEcon.update_values!-Tuple{QuantEcon.LQ}"><code>QuantEcon.update_values!</code></a></li><li><a href="QuantEcon.html#QuantEcon.value_simulation"><code>QuantEcon.value_simulation</code></a></li><li><a href="QuantEcon.html#QuantEcon.var_quadratic_sum-Tuple{Union{Array{T,N},T},Union{Array{T,N},T},Union{Array{T,N},T},Real,Union{Array{T,N},T}}"><code>QuantEcon.var_quadratic_sum</code></a></li></ul><footer><hr/><a class="previous" href="../index.html"><span class="direction">Previous</span><span class="title">Home</span></a><a class="next" href="../man/contributing.html"><span class="direction">Next</span><span class="title">Contributing</span></a></footer></article></body></html>
